Env:main:Test 0
Env:main:Test 0
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 0: 1
Env:main:Test 1
Env:main:Test 1
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 1: 0
Env:main:Test 2
Env:main:Test 2
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 2: 0
Env:main:Test 3
Env:main:Test 3
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 3: 0
Env:main:Test 4
Env:main:Test 4
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 4: 0
Env:main:Test 5
Env:main:Test 5
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 5: 0
Env:main:Test 6
Env:main:Test 6
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 6: 0
Env:main:Test 7
Env:main:Test 7
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 7: 0
Env:main:Test 8
Env:main:Test 8
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: w -> <6, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.1,<6, 0>=0.8,<6, 1>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#bb   #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<6, 0>=0.888888,<6, 1>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
#     #
#bb   #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 0>=0.711111,<5, 1>=0.088888,<6, 0>=0.099999,<6, 1>=0.088888,<6, 2>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# B   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#     #
#     #
#     #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#     #
#     #
#     #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 47.3534626946
Env:runForbidden:All agents are done, Sum of discounted rewards: 95.7496086946
Env:main:Time of iteration 8: 0
Env:main:Test 9
Env:main:Test 9
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 9: 1
Env:main:Test 10
Env:main:Test 10
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 10: 1
Env:main:Test 11
Env:main:Test 11
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 11: 0
Env:main:Test 12
Env:main:Test 12
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 12: 0
Env:main:Test 13
Env:main:Test 13
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 13: 0
Env:main:Test 14
Env:main:Test 14
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<6, 0>=1.0]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
#     #
#b    #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 0>=0.8,(<6, 0>-<6, 1>)=0.1]
#######
#   a #
#  a a#
# a a #
##   ##
# B   #
#b    #
#bb   #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.639999,(<5, 0>-<5, 1>)=0.159999,<6, 0>=0.019999]
#######
#     #
#     #
#     #
##   ##
#bB   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: ping_to_<5,2> -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.771084,<5, 0>=0.192771,<6, 0>=0.024096,<6, 1>=0.012048]
#######
#     #
#     #
#     #
##   ##
#bB   #
#b    #
#bb   #
#######

GridAgent:step:Agent b: n -> <4, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.848192,<4, 1>=0.077108,<5, 0>=0.038554,<5, 1>=0.028915]
#######
#     #
#     #
#     #
##   ##
#bb   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: ping_to_<5,2> -> <4, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.950067,<5, 0>=0.043184]
#######
#     #
#     #
#     #
##   ##
#bB   #
#b    #
#bb   #
#######

GridAgent:step:Agent b: e -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.099325,<4, 1>=0.760053,<5, 0>=0.095411,<5, 1>=0.034817]
#######
#     #
#     #
#     #
##   ##
#bb   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 94.22435949910768
Env:main:Time of iteration 14: 0
Env:main:Test 15
Env:main:Test 15
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 15: 0
Env:main:Test 16
Env:main:Test 16
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 4>=1.0]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#     #
#    a#
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 4>=0.8,(<2, 3>-<2, 4>)=0.1]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   A #
#    a#
#   aa#
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: n -> <0, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.639999,(<1, 3>-<1, 4>)=0.159999,<2, 4>=0.019999]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
#######
#   Aa#
#   aa#
#  aaa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <0, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.771084,<1, 4>=0.192771,<2, 3>=0.012048,<2, 4>=0.024096]
#######
#   Aa#
#    a#
#   aa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: n -> <0, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.077108,<0, 4>=0.848192,<1, 3>=0.028915,<1, 4>=0.038554]
#######
#   aa#
#   aa#
#  aaa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <0, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.950067,<1, 4>=0.043184]
#######
#   Aa#
#    a#
#   aa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: w -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.760053,<0, 4>=0.099325,<1, 3>=0.034817,<1, 4>=0.095411]
#######
#   aa#
#   aa#
#  aaa#
##  a##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 94.22435949910768
Env:main:Time of iteration 16: 0
Env:main:Test 17
Env:main:Test 17
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 2> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <6, 3> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: -39.049568
Env:main:Time of iteration 17: 0
Env:main:Test 18
Env:main:Test 18
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 18: 0
Env:main:Test 19
Env:main:Test 19
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 19: 0
Env:main:Test 20
Env:main:Test 20
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 20: 0
Env:main:Test 21
Env:main:Test 21
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 21: 0
Env:main:Test 22
Env:main:Test 22
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 22: 0
Env:main:Test 23
Env:main:Test 23
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 23: 0
Env:main:Test 24
Env:main:Test 24
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 24: 0
Env:main:Test 25
Env:main:Test 25
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 2> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 25: 0
Env:main:Test 26
Env:main:Test 26
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 26: 0
Env:main:Test 27
Env:main:Test 27
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 27: 0
Env:main:Test 28
Env:main:Test 28
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<6, 0>=1.0]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
#     #
#b    #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <6, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 0>=0.8,(<6, 0>-<6, 1>)=0.1]
#######
#   a #
#  a a#
# a a #
##   ##
# B   #
#b    #
#bb   #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.639999,(<5, 0>-<5, 1>)=0.159999,<6, 0>=0.019999]
#######
#     #
#     #
#     #
##   ##
#bB   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.941176,<6, 2>=0.058823]
#######
#     #
#     #
#     #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.752941,<5, 0>=0.094117,<5, 2>=0.141176]
#######
#     #
#     #
#     #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
Env:runForbidden:All agents are done, Sum of discounted rewards: 29.332463609584003
Env:main:Time of iteration 28: 0
Env:main:Test 29
Env:main:Test 29
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: -39.049568
Env:main:Time of iteration 29: 0
Env:main:Test 30
Env:main:Test 30
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 30: 0
Env:main:Test 31
Env:main:Test 31
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 31: 0
Env:main:Test 32
Env:main:Test 32
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 2> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: -39.049568
Env:main:Time of iteration 32: 0
Env:main:Test 33
Env:main:Test 33
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<6, 0>=1.0]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
#     #
#b    #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 0>=0.8,(<6, 0>-<6, 1>)=0.1]
#######
#   a #
#  a a#
# a a #
##   ##
# B   #
#b    #
#bb   #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.639999,(<5, 0>-<5, 1>)=0.159999,<6, 0>=0.019999]
#######
#     #
#     #
#     #
##   ##
#bB   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.941176,<6, 2>=0.058823]
#######
#     #
#     #
#     #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.752941,<5, 0>=0.094117,<5, 2>=0.141176]
#######
#     #
#     #
#     #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.315144067653993
Env:main:Time of iteration 33: 0
Env:main:Test 34
Env:main:Test 34
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: -39.049568
Env:main:Time of iteration 34: 0
Env:main:Test 35
Env:main:Test 35
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 35: 0
Env:main:Test 36
Env:main:Test 36
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 36: 0
Env:main:Test 37
Env:main:Test 37
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 2> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 37: 0
Env:main:Test 38
Env:main:Test 38
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<6, 0>=1.0]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
#     #
#b    #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 0>=0.8,(<6, 0>-<6, 1>)=0.1]
#######
#   a #
#  a a#
# a a #
##   ##
# B   #
#b    #
#bb   #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: n -> <4, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.639999,(<5, 0>-<5, 1>)=0.159999,<6, 0>=0.019999]
#######
#     #
#     #
#     #
##   ##
#bB   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: ping_to_<5,2> -> <4, 0> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.771084,<5, 0>=0.192771,<6, 0>=0.024096,<6, 1>=0.012048]
#######
#     #
#     #
#     #
##   ##
#bB   #
#b    #
#bb   #
#######

GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.848192,<4, 1>=0.077108,<5, 0>=0.038554,<5, 1>=0.028915]
#######
#     #
#     #
#     #
##   ##
#bb   #
#bb   #
#bbb  #
#######

GridAgent:step:Agent b: ping_to_<5,2> -> DONE O: DONE_OBS R: -0.04
GridAgent:step:Agent b done! discounted reward: -0.27173860837204
Env:runForbidden:All agents are done, Sum of discounted rewards: -19.79652260837204
Env:main:Time of iteration 38: 0
Env:main:Test 39
Env:main:Test 39
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 39: 0
Env:main:Test 40
Env:main:Test 40
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 2> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 40: 0
Env:main:Test 41
Env:main:Test 41
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 4>=1.0]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#     #
#    a#
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <2, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 4>=0.8,(<2, 3>-<2, 4>)=0.1]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   A #
#    a#
#   aa#
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.639999,(<1, 3>-<1, 4>)=0.159999,<2, 4>=0.019999]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
#######
#   Aa#
#   aa#
#  aaa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.941176,<2, 2>=0.058823]
#######
#   A #
#   a #
#  a  #
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.752941,<1, 2>=0.141176,<1, 4>=0.094117]
#######
#   a #
#  a a#
# a a #
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 95.23607406765399
Env:main:Time of iteration 41: 0
Env:main:Test 42
Env:main:Test 42
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 42: 0
Env:main:Test 43
Env:main:Test 43
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 4>=1.0]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#     #
#    a#
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <2, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 4>=0.8,(<2, 3>-<2, 4>)=0.1]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   A #
#    a#
#   aa#
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.639999,(<1, 3>-<1, 4>)=0.159999,<2, 4>=0.019999]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
#######
#   Aa#
#   aa#
#  aaa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.941176,<2, 2>=0.058823]
#######
#   A #
#   a #
#  a  #
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.752941,<1, 2>=0.141176,<1, 4>=0.094117]
#######
#   a #
#  a a#
# a a #
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.063682390415998
Env:runForbidden:All agents are done, Sum of discounted rewards: 29.332463609584003
Env:main:Time of iteration 43: 0
Env:main:Test 44
Env:main:Test 44
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 44: 0
Env:main:Test 45
Env:main:Test 45
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 45: 0
Env:main:Test 46
Env:main:Test 46
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 96.792292
Env:main:Time of iteration 46: 0
Env:main:Test 47
Env:main:Test 47
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <6, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 4>=1.0]
GridAgent:step:Agent b: ping_to_<5,2> -> <6, 2> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#     #
#    a#
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 4>=0.8,(<2, 3>-<2, 4>)=0.1]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   A #
#    a#
#   aa#
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: n -> <0, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.639999,(<1, 3>-<1, 4>)=0.159999,<2, 4>=0.019999]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
#######
#   Aa#
#   aa#
#  aaa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <0, 4> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 4>=0.771084,<1, 4>=0.192771,<2, 3>=0.012048,<2, 4>=0.024096]
#######
#   Aa#
#    a#
#   aa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.077108,<0, 4>=0.848192,<1, 3>=0.028915,<1, 4>=0.038554]
#######
#   aa#
#   aa#
#  aaa#
##   ##
#     #
#     #
#     #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> DONE O: DONE_OBS R: -0.04
GridAgent:step:Agent a done! discounted reward: -0.27173860837204
Env:runForbidden:All agents are done, Sum of discounted rewards: -19.79652260837204
Env:main:Time of iteration 47: 0
Env:main:Test 48
Env:main:Test 48
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <1, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <1, 3> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <0, 3> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <5, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 48.396146
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.524784
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 48: 0
Env:main:Test 49
Env:main:Test 49
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <2, 3>
Env:runForbidden:Agent b starts at <6, 1>
#######
#   A #
#     #
#   a #
##   ##
# B   #
#     #
# b   #
#######

GridAgent:step:Agent a: n -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.8,<2, 2>=0.1,<2, 4>=0.1]
GridAgent:step:Agent b: n -> <5, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.8,<6, 0>=0.1,<6, 2>=0.1]
#######
#   A #
#   a #
#  a a#
##   ##
# B   #
# b   #
#b b  #
#######

GridAgent:step:Agent a: ping_to_<1,2> -> <2, 2> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.888888,<2, 2>=0.111111]
GridAgent:step:Agent b: ping_to_<5,2> -> <5, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<5, 1>=0.888888,<6, 2>=0.111111]
#######
#   A #
#   a #
#  a  #
##   ##
# B   #
# b   #
#  b  #
#######

GridAgent:step:Agent a: n -> <1, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.711111,<1, 2>=0.177777,<1, 4>=0.088888,<2, 1>=0.011111,<2, 3>=0.011111]
GridAgent:step:Agent b: n -> <4, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.711111,<5, 0>=0.088888,<5, 2>=0.177777,<6, 1>=0.011111,<6, 3>=0.011111]
#######
#   a #
#  a a#
# a a #
##   ##
# b   #
#b b  #
# b b #
#######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 48.396146
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.871362
Env:main:Time of iteration 49: 0
Env:main:Sum of discounted rewards: [96.792, 28.871, 96.792, 96.792, 28.871, 28.871, 96.792, 96.792, 95.75, 28.871, 96.792, 28.871, 96.792, 28.871, 94.224, 28.871, 94.224, -39.05, 96.792, 28.871, 28.871, 96.792, 96.792, 96.792, 96.792, 28.871, 96.792, 28.871, 29.332, -39.05, 96.792, 96.792, -39.05, 27.315, -39.05, 96.792, 28.871, 28.871, -19.797, 28.871, 28.871, 95.236, 96.792, 29.332, 96.792, 28.871, 96.792, -19.797, 28.871, 28.871]
Env:main:ADR: 52.56722439661096
Env:main:std: 6.328961539392119
Env:main:46% Solved
Env:main:Time elapsed (s): 31
Env:main:Average runtime (s): 0.62
Env:main:parameters:
Env:main:	initialTimer: 10
Env:main:	distanceThreshold: 2
