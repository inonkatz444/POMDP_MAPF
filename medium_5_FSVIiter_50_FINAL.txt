Env:main:Test 0
Env:main:Test 0
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.763915110846717
Env:runForbidden:All agents are done, Sum of discounted rewards: -38.28869911084672
Env:main:Time of iteration 0: 18
Env:main:Test 1
Env:main:Test 1
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
# a  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#  a #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#    #
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#    #
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.806744786977458
Env:main:Time of iteration 1: 7
Env:main:Test 2
Env:main:Test 2
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
#aa  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.027272,<0, 1>=0.072727,<1, 0>=0.027272,<1, 1>=0.218181,<1, 2>=0.581818,<2, 1>=0.072727]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#aaa #
##a ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.095076,<1, 0>=0.035653,<1, 1>=0.095076,<1, 2>=0.760611,<2, 1>=0.013582]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#aaa #
##a ##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.102788,<1, 0>=0.038545,<1, 1>=0.034262,<1, 2>=0.822305]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#aaa #
##a ##
#   b#
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.013705,<0, 2>=0.164461,<1, 1>=0.041325,<1, 2>=0.027410,<1, 3>=0.657844,<2, 2>=0.083908]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.047080,<3, 3>=0.026277,<4, 0>=0.05,<4, 1>=0.4,<4, 2>=0.047080,<4, 3>=0.379562]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aaaa#
##aa##
#babb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.199066,<1, 3>=0.796267]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.020373,<0, 3>=0.019906,<1, 2>=0.238880,<1, 3>=0.716640]
######
#aa a#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.077468,<1, 0>=0.014192,<1, 2>=0.908338]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.152808,<1, 1>=0.019101,<1, 3>=0.726670,<2, 2>=0.090833]
######
#aaaA#
#aa a#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.173469,<1, 3>=0.824919]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.017508,<0, 3>=0.017346,<1, 2>=0.221267,<1, 3>=0.742427]
######
#aa a#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.999783]
######
#a  A#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.799826,(<1, 2>-<1, 3>)=0.099978]
######
#aa a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -17.89993300430365
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.93999506335034
Env:main:Time of iteration 2: 64
Env:main:Test 3
Env:main:Test 3
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.75,<3, 1>=0.25]
######
#aa A#
#aaa #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.075000,<3, 2>=0.025,<4, 0>=0.600000,<4, 1>=0.2]
######
# a A#
#aaa #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aaaA#
#aaaa#
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aaaa#
##aa##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
GridAgent:decreaseTimer:Agent b timer: 0
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.65642699821535
Env:main:Time of iteration 3: 14
Env:main:Test 4
Env:main:Test 4
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#   A#
#aa  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.218181,<0, 1>=0.581818,<1, 0>=0.099999,<1, 1>=0.027272,<1, 2>=0.072727]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#aaa #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.334545,<0, 1>=0.509090,<0, 2>=0.116363,<1, 0>=0.012727,<1, 1>=0.017272]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
#aaaa#
##  ##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.730158,<0, 2>=0.253968,<1, 3>=0.015873]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.657142,<0, 1>=0.203174,<0, 2>=0.025396,<1, 0>=0.073015,<1, 2>=0.038095]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.047080,<3, 3>=0.026277,<4, 0>=0.05,<4, 1>=0.4,<4, 2>=0.047080,<4, 3>=0.379562]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.960556,<0, 2>=0.037122]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.864501,<0, 1>=0.029698,<1, 0>=0.096055]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.096077,<0, 1>=0.694731,<0, 2>=0.024692,<1, 0>=0.096077,<1, 1>=0.079832]
######
#aaaa#
#aaaa#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.765957,<0, 2>=0.196854,<1, 3>=0.037187]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.689361,<0, 1>=0.157483,<0, 2>=0.019685,<1, 0>=0.076595,<1, 2>=0.049435]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.555468,<1, 0>=0.270164,<1, 2>=0.174367]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.271678,<0, 1>=0.444374,<0, 2>=0.195040,<1, 0>=0.027016,<1, 1>=0.044453,<1, 3>=0.017436]
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.561138,<0, 2>=0.402846,<1, 3>=0.036014]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.505024,<0, 1>=0.322277,<0, 2>=0.040284,<1, 0>=0.056113,<1, 2>=0.069096]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.920048,<0, 2>=0.073390]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.828043,<0, 1>=0.058712,<1, 0>=0.092004,<1, 2>=0.012587]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.092065,<0, 1>=0.668745,<0, 2>=0.048994,<1, 0>=0.092065,<1, 1>=0.079527,<1, 3>=0.010667]
######
#aaaa#
#aaaa#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.606779,<0, 2>=0.322911,<1, 3>=0.070309]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.546101,<0, 1>=0.258328,<0, 2>=0.032291,<1, 0>=0.060677,<1, 2>=0.088538]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.932831,<0, 2>=0.055158,<1, 3>=0.012009]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.839548,<0, 1>=0.044126,<1, 0>=0.093283,<1, 2>=0.015123]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.093395,<0, 1>=0.676864,<0, 2>=0.037410,<1, 0>=0.093395,<1, 1>=0.079134,<1, 3>=0.013195]
######
#aaaa#
#aaaa#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.848525,<1, 0>=0.117081,<1, 1>=0.033067]
######
# a A#
#aaa #
## a##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011708,<0, 1>=0.088159,<0, 2>=0.678889,<1, 0>=0.011708,<1, 1>=0.178517,<1, 2>=0.026517]
######
#aaaA#
#aaaa#
##aa##
#  a #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.016940,<0, 2>=0.982258]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.013552,<0, 2>=0.098225,<0, 3>=0.785887,<1, 2>=0.098225]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 37.16650657474359
Env:runForbidden:All agents are done, Sum of discounted rewards: 18.102824184327595
Env:main:Time of iteration 4: 35
Env:main:Test 5
Env:main:Test 5
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#a  A#
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aa A#
#a   #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.66146015109406
Env:main:Time of iteration 5: 4
Env:main:Test 6
Env:main:Test 6
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,(<3, 1>-<3, 2>)=0.01,<4, 0>=0.799999,<4, 1>=0.16]
######
#aa A#
#aaa #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.103448,<3, 1>=0.017241,<3, 2>=0.051724,<4, 1>=0.827586]
######
# a A#
#aaa #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.012068,<3, 1>=0.015517,<4, 0>=0.165517,<4, 1>=0.675862,<4, 2>=0.124137]
######
#aaaA#
#aaaa#
##  ##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017369,<4, 1>=0.972704]
######
# a A#
#aaa #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.111028,<0, 1>=0.785625,<0, 2>=0.097645]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111166,<4, 1>=0.098014,<4, 2>=0.778411]
######
#aaaA#
#aaaa#
##bb##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <1, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.994379]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.995241]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#aaa #
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099513,<0, 2>=0.795637,<1, 1>=0.102261]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099524,<4, 2>=0.099524,<4, 3>=0.796446]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aaaa#
##aa##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998219]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099821,<0, 3>=0.798709,<1, 2>=0.099821]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.83663205047543
Env:runForbidden:All agents are done, Sum of discounted rewards: 90.6648455495831
Env:main:Time of iteration 6: 24
Env:main:Test 7
Env:main:Test 7
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
# a  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.6816
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 1
######
#    #
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#b   #
#bb B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#    #
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#    #
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#    #
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.015228,<3, 1>=0.010152,<4, 1>=0.974619]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109644,<4, 1>=0.098477,<4, 2>=0.779695]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998050]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099805,<4, 2>=0.099805,<4, 3>=0.798440]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 43.38613524194427
Env:runForbidden:All agents are done, Sum of discounted rewards: 23.704535241944267
Env:main:Time of iteration 7: 18
Env:main:Test 8
Env:main:Test 8
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#a  A#
#    #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.072727,<3, 0>=0.027272,<3, 1>=0.218181,<3, 2>=0.581818,<4, 0>=0.027272,<4, 1>=0.072727]
######
#aa A#
#a   #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.124999,<3, 1>=0.875]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##b ##
# b  #
#   B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.057692,<3, 1>=0.942307]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##b ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.025568,<3, 1>=0.974431]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##b ##
# b  #
#   B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.097443,<2, 2>=0.020454,<3, 2>=0.779545,<4, 1>=0.097443]
######
#aaaa#
#aba #
##bb##
# bb #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.172272,<3, 1>=0.019488,<3, 3>=0.623636,<4, 1>=0.01,<4, 2>=0.155909]
######
# b  #
# bb #
##bb##
# bbb#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.879875,<3, 1>=0.099537]
######
# b  #
# bb #
##bb##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.096062,<2, 2>=0.095263,<3, 2>=0.713853,<4, 1>=0.079629]
######
#b b #
#bbbb#
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<1, 1>=0.010402,<1, 2>=0.010606,<2, 2>=0.224545,<3, 1>=0.025532,<3, 2>=0.010242,<3, 3>=0.571083,<4, 2>=0.135089]
######
#bbbb#
#bbbb#
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.807563,<4, 2>=0.191028]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.233579,<3, 3>=0.726807,<4, 1>=0.019243,<4, 3>=0.019102]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.919788,<4, 1>=0.075777]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.091978,<3, 1>=0.011125,<3, 3>=0.735830,<4, 2>=0.152600]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.827822,<4, 2>=0.171678]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.220125,<3, 3>=0.745040,<4, 1>=0.017217,<4, 3>=0.017167]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.999933]
######
#    #
#    #
##  ##
#   b#
#b  B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.099993,<4, 3>=0.799946]
######
#    #
#    #
##  ##
#  bb#
#bb b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 40.613105687121674
Env:runForbidden:All agents are done, Sum of discounted rewards: 86.94463447409913
Env:main:Time of iteration 8: 45
Env:main:Test 9
Env:main:Test 9
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
# a  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#  a #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#    #
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#    #
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.806744786977458
Env:main:Time of iteration 9: 8
Env:main:Test 10
Env:main:Test 10
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aa A#
#aaa #
##  ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#aaa #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aaaa#
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.5,<0, 2>=0.470802,<1, 3>=0.029197]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#   a#
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.050000,<0, 1>=0.400000,<0, 2>=0.047080,<0, 3>=0.379562,<1, 0>=0.050000,<1, 2>=0.047080,<1, 3>=0.026277]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
######
#aaaa#
#a aa#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.67985613530799
Env:main:Time of iteration 10: 31
Env:main:Test 11
Env:main:Test 11
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
# a  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#  a #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
# a a#
##aa##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#a aA#
#   a#
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaa#
#a aa#
##  ##
#    #
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.17145685463146
Env:main:Time of iteration 11: 6
Env:main:Test 12
Env:main:Test 12
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#a  A#
#    #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.072727,<3, 0>=0.027272,<3, 1>=0.218181,<3, 2>=0.581818,<4, 0>=0.027272,<4, 1>=0.072727]
######
#aa A#
#a   #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.013582,<3, 0>=0.035653,<3, 1>=0.095076,<3, 2>=0.760611,<4, 1>=0.095076]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa  #
##b ##
#bbb #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.685714,<1, 0>=0.085714,<1, 1>=0.228571]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.038545,<3, 1>=0.034262,<3, 2>=0.822305,<4, 1>=0.102788]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#aa  #
##b ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.137142,<0, 1>=0.731428,<0, 2>=0.068571,<1, 0>=0.031428,<1, 2>=0.022857]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.039519,<3, 1>=0.011709,<3, 2>=0.843079,<4, 1>=0.105384]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aaa #
##b ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.927536,<1, 0>=0.039855,<1, 2>=0.028985]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.093115,<0, 2>=0.744927,<1, 1>=0.124637,<1, 3>=0.023188]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.964805,<1, 3>=0.030032]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.096480,<0, 3>=0.774847,<1, 2>=0.096480,<1, 3>=0.027029]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.83663205047543
Env:runForbidden:All agents are done, Sum of discounted rewards: 25.77294966005943
Env:main:Time of iteration 12: 26
Env:main:Test 13
Env:main:Test 13
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.02,<0, 1>=0.16,<1, 0>=0.02,<1, 1>=0.08,<1, 2>=0.64,<2, 1>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##a ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.186459,<1, 0>=0.023307,<1, 1>=0.031076,<1, 2>=0.745837,<2, 1>=0.013318]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#aaa #
##a ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.192650,<1, 0>=0.024081,<1, 1>=0.010702,<1, 2>=0.770600]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#aaa #
##a ##
#bb  #
#bbbB#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.36953616
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.085714,<3, 1>=0.228571,<4, 1>=0.685714]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#    #
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.015228,<3, 1>=0.010152,<4, 1>=0.974619]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109644,<4, 1>=0.098477,<4, 2>=0.779695]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998050]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099805,<4, 2>=0.099805,<4, 3>=0.798440]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 43.864783072670974
Env:runForbidden:All agents are done, Sum of discounted rewards: 24.495246912670975
Env:main:Time of iteration 13: 11
Env:main:Test 14
Env:main:Test 14
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.685714,<1, 0>=0.085714,<1, 1>=0.228571]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
# a A#
#aa  #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#   A#
# a  #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974619,<1, 0>=0.015228,<1, 1>=0.010152]
######
# a A#
#aa  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098477,<0, 2>=0.779695,<1, 1>=0.109644]
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998050]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099805,<0, 3>=0.798440,<1, 2>=0.099805]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.182157947458066
Env:runForbidden:All agents are done, Sum of discounted rewards: -37.245840337874064
Env:main:Time of iteration 14: 5
Env:main:Test 15
Env:main:Test 15
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#a   #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#a   #
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
######
#aaaA#
#aa  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.16985943177059
Env:main:Time of iteration 15: 29
Env:main:Test 16
Env:main:Test 16
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#a   #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
#aa  #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#   A#
# a  #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
# a A#
#a a #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaA#
#aa a#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974619,<1, 0>=0.015228,<1, 1>=0.010152]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
######
# a A#
#aa  #
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098477,<0, 2>=0.779695,<1, 1>=0.109644]
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998050]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099805,<0, 3>=0.798440,<1, 2>=0.099805]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 43.864783072670974
Env:runForbidden:All agents are done, Sum of discounted rewards: 89.69299657177865
Env:main:Time of iteration 16: 17
Env:main:Test 17
Env:main:Test 17
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aa A#
#aaa #
##  ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#aaa #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aaaa#
##  ##
#bb b#
#bbbB#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.030303,<4, 0>=0.484848,<4, 2>=0.484848]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#aaa #
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.978369,<1, 0>=0.017470]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: w -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.048484,<3, 2>=0.072727,<4, 0>=0.436363,<4, 1>=0.387878,<4, 2>=0.048484]
######
# a A#
#aaa #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.980681,<1, 0>=0.017512]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.012158,<4, 0>=0.471732,<4, 1>=0.359878,<4, 2>=0.136170]
######
# a A#
#aaa #
##  ##
#bbbb#
#bbbb#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.112077,<0, 1>=0.785489,<0, 2>=0.098568]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.013175,<3, 1>=0.010979,<4, 1>=0.975020]
######
#aaaA#
#aaaa#
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.996710]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.108042,<4, 1>=0.098600,<4, 2>=0.780098]
######
# a A#
#aaa #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.101568,<0, 1>=0.797982,<0, 2>=0.099791]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997472]
######
#aaaA#
#aaaa#
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.999405]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099747,<4, 2>=0.099747,<4, 3>=0.798062]
######
# a A#
#aaa #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099951,<0, 2>=0.799533,<1, 1>=0.100255]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.32541206813946
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.999854]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099985,<0, 3>=0.799893,<1, 2>=0.099985]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 42.91227388952482
Env:runForbidden:All agents are done, Sum of discounted rewards: 24.58686182138536
Env:main:Time of iteration 17: 38
Env:main:Test 18
Env:main:Test 18
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#   A#
# a  #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: n -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
# a A#
#a a #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa a#
##bb##
# b b#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.484848,<0, 2>=0.484848,<1, 3>=0.030303]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#a aA#
#   a#
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.048484,<0, 1>=0.387878,<0, 2>=0.048484,<0, 3>=0.390909,<1, 0>=0.048484,<1, 2>=0.048484,<1, 3>=0.027272]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaa#
#a aa#
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.063682390415998
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.776245677237995
Env:main:Time of iteration 18: 18
Env:main:Test 19
Env:main:Test 19
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.085714,<3, 1>=0.228571,<4, 1>=0.685714]
######
#a aA#
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.101123,<3, 1>=0.089887,<4, 1>=0.808988]
######
#aaaa#
#a a #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.107569,<3, 1>=0.031872,<4, 1>=0.860557]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109905,<3, 1>=0.010854,<4, 1>=0.879240]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010990,<3, 1>=0.175848,<4, 0>=0.010990,<4, 1>=0.089009,<4, 2>=0.703392]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 44.34826572997068
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.18819379762468
Env:main:Time of iteration 19: 5
Env:main:Test 20
Env:main:Test 20
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
# a A#
#a   #
##  ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
######
#aaaA#
#aa  #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111028,<4, 1>=0.098203,<4, 2>=0.777261]
######
#a aA#
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997138]
######
#aaaa#
#a a #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099713,<4, 2>=0.099713,<4, 3>=0.797774]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.15974228608513
Env:main:Time of iteration 20: 4
Env:main:Test 21
Env:main:Test 21
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <2, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.02,<0, 1>=0.16,<1, 0>=0.02,<1, 1>=0.08,<1, 2>=0.64,<2, 1>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: s -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#aa A#
#aaa #
##a ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 1> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#   A#
#    #
##a ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=0.8,(<2, 1>-<2, 2>)=0.1]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#   A#
# a  #
##aa##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.36953616
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: w -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.070437,<4, 0>=0.45,<4, 1>=0.376642,<4, 2>=0.047080]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.100587,<3, 2>=0.141703,<4, 1>=0.757709]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: s -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010058,<3, 1>=0.024229,<3, 3>=0.014170,<4, 0>=0.156240,<4, 1>=0.606167,<4, 2>=0.189133]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.039411,<4, 0>=0.434551,<4, 2>=0.526036]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: w -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.043455,<3, 2>=0.084133,<4, 0>=0.391096,<4, 1>=0.420829,<4, 2>=0.052603]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: s -> DONE O: DONE_OBS R: -0.04
GridAgent:step:Agent b done! discounted reward: -0.4186469829651342
Env:runForbidden:All agents are done, Sum of discounted rewards: -19.788183142965135
Env:main:Time of iteration 21: 16
Env:main:Test 22
Env:main:Test 22
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.303429499107676
Env:main:Time of iteration 22: 23
Env:main:Test 23
Env:main:Test 23
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
#aa  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.027272,<0, 1>=0.072727,<1, 0>=0.027272,<1, 1>=0.218181,<1, 2>=0.581818,<2, 1>=0.072727]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#aaa #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.095076,<1, 0>=0.035653,<1, 1>=0.095076,<1, 2>=0.760611,<2, 1>=0.013582]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#aaa #
##a ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.102788,<1, 0>=0.038545,<1, 1>=0.034262,<1, 2>=0.822305]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
# a A#
#aaa #
##a ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.105384,<1, 0>=0.039519,<1, 1>=0.011709,<1, 2>=0.843079]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
# a A#
#aaa #
##a ##
#    #
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.011709,<0, 2>=0.168615,<1, 1>=0.042184,<1, 3>=0.674463,<2, 2>=0.084553]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaA#
#aaaa#
##aa##
#bab #
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.199066,<1, 3>=0.796267]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.913045566511837
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.020373,<0, 3>=0.019906,<1, 2>=0.238880,<1, 3>=0.716640]
######
#aa a#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.999349]
######
#a  A#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.799479,(<1, 2>-<1, 3>)=0.099934]
######
#aa a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.34826572997068
Env:runForbidden:All agents are done, Sum of discounted rewards: 25.43522016345884
Env:main:Time of iteration 23: 9
Env:main:Test 24
Env:main:Test 24
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
# a A#
#a   #
##  ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
######
#aaaA#
#aa  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.558139,<1, 0>=0.069767,<1, 1>=0.372093]
GridAgent:step:Agent b: w -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.070437,<4, 0>=0.45,<4, 1>=0.376642,<4, 2>=0.047080]
######
# a A#
#aa  #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.100587,<3, 2>=0.141703,<4, 1>=0.757709]
######
#   A#
# a  #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010058,<3, 1>=0.024229,<3, 3>=0.014170,<4, 0>=0.156240,<4, 1>=0.606167,<4, 2>=0.189133]
######
# a A#
#a a #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.039411,<4, 0>=0.434551,<4, 2>=0.526036]
######
#aaaA#
#aa a#
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.484848,<0, 2>=0.484848,<1, 3>=0.030303]
GridAgent:step:Agent b: w -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.043455,<3, 2>=0.084133,<4, 0>=0.391096,<4, 1>=0.420829,<4, 2>=0.052603]
######
#a aA#
#   a#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: w -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.436363,<0, 1>=0.387878,<0, 2>=0.048484,<1, 0>=0.048484,<1, 2>=0.072727]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.079237,<3, 2>=0.153410,<4, 1>=0.767351]
######
#aaaa#
#a aa#
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.761904,<1, 0>=0.095238,<1, 2>=0.142857]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.023264,<3, 3>=0.015341,<4, 0>=0.140125,<4, 1>=0.613881,<4, 2>=0.199463]
######
# a A#
#a a #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.152380,<0, 1>=0.609523,<0, 2>=0.190476,<1, 1>=0.023809,<1, 3>=0.014285]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.012586,<3, 1>=0.012318,<4, 1>=0.975095]
######
#aaaA#
#aa a#
##  ##
#bb  #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.040336367983485
######
#   A#
# a  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.484848,<0, 2>=0.484848,<1, 3>=0.030303]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.436363,<0, 1>=0.387878,<0, 2>=0.048484,<1, 0>=0.048484,<1, 2>=0.072727]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.761904,<1, 0>=0.095238,<1, 2>=0.142857]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.152380,<0, 1>=0.609523,<0, 2>=0.190476,<1, 1>=0.023809,<1, 3>=0.014285]
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.972151,<1, 0>=0.015189,<1, 1>=0.012658]
######
# a A#
#aa  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098481,<0, 2>=0.777721,<1, 1>=0.109367,<1, 2>=0.010126]
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998050]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099805,<0, 3>=0.798440,<1, 2>=0.099805]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 38.42661960358981
Env:runForbidden:All agents are done, Sum of discounted rewards: 20.386283235606328
Env:main:Time of iteration 24: 17
Env:main:Test 25
Env:main:Test 25
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66305757395492
Env:main:Time of iteration 25: 30
Env:main:Test 26
Env:main:Test 26
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: s -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##bb##
# b b#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.024590,<2, 2>=0.057377,<3, 1>=0.918032]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##bb##
# b  #
#   B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.010688,<2, 2>=0.058194,<3, 1>=0.931116]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##bb##
# b  #
#   B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <1, 2>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: ping_to_<3,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.018397,<2, 2>=0.233714,<3, 1>=0.747887]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaa#
#a a #
##bb##
# b  #
#   B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.913045566511837
GridAgent:step:Agent b: ping_to_<3,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.020156,<2, 2>=0.597465,<3, 1>=0.382378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#    #
#    #
##bb##
# b  #
#   B#
######

GridAgent:step:Agent b: ping_to_<3,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.012655,<2, 2>=0.875305,<3, 1>=0.112039]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##bb##
# b  #
#   B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: ping_to_<3,1> -> <3, 1> O: 1 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.194877,<3, 1>=0.805122]
######
#    #
#    #
##b ##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<2, 1>-<2, 2>)=0.019487,<3, 0>=0.080512,<3, 1>=0.155901,<3, 2>=0.080512,<4, 1>=0.644098]
######
#    #
#    #
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.092930,<3, 1>=0.059982,<3, 2>=0.092930,<4, 1>=0.743444]
######
#    #
#    #
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.015291,<3, 1>=0.021156,<3, 2>=0.011996,<4, 0>=0.148688,<4, 1>=0.642742,<4, 2>=0.148688]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.030303,<4, 0>=0.484848,<4, 2>=0.484848]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: w -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.048484,<3, 2>=0.072727,<4, 0>=0.436363,<4, 1>=0.387878,<4, 2>=0.048484]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.012158,<4, 0>=0.471732,<4, 1>=0.359878,<4, 2>=0.136170]
######
#    #
#    #
##  ##
#bbbb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.012345,<4, 0>=0.766419,<4, 2>=0.221234]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: w -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.076641,<3, 2>=0.031999,<4, 0>=0.689777,<4, 1>=0.176987,<4, 2>=0.022123]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.010877,<4, 0>=0.700677,<4, 1>=0.213043,<4, 2>=0.061072]
######
#    #
#    #
##  ##
#bbbb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.915824,<4, 2>=0.079825]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.824242,<4, 1>=0.099565,<4, 2>=0.063860,<4, 3>=0.011462]
######
#    #
#    #
##  ##
#  bb#
#bbbb#
######

GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.760491,<4, 1>=0.170415,<4, 2>=0.062104]
######
#    #
#    #
##  ##
# bbb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.924402,<4, 2>=0.075490]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.831962,<4, 1>=0.099989,<4, 2>=0.060392]
######
#    #
#    #
##  ##
#  bb#
#bbbb#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.764602,<4, 1>=0.170528,<4, 2>=0.058770]
######
#    #
#    #
##  ##
# bbb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.999991]
######
#    #
#    #
##  ##
# bb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.099999,<4, 1>=0.099999,<4, 2>=0.799993]
######
#    #
#    #
##bb##
# bbb#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.999993]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099999,<4, 2>=0.099999,<4, 3>=0.799995]
######
#    #
#    #
##  ##
#  bb#
#  bb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -15.954753509305538
Env:runForbidden:All agents are done, Sum of discounted rewards: -34.86779907581737
Env:main:Time of iteration 26: 16
Env:main:Test 27
Env:main:Test 27
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.303429499107676
Env:main:Time of iteration 27: 22
Env:main:Test 28
Env:main:Test 28
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#   A#
# a  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
# a A#
#  a #
##a ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
# a a#
##aa##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.047080,<3, 3>=0.026277,<4, 0>=0.05,<4, 1>=0.4,<4, 2>=0.047080,<4, 3>=0.379562]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
GridAgent:decreaseTimer:Agent b timer: 0
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.776245677237995
Env:main:Time of iteration 28: 17
Env:main:Test 29
Env:main:Test 29
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aa A#
#aaa #
##  ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.6816
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:decreaseTimer:Agent a timer: 0
######
#aaaA#
#aaaa#
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.146613499107676
Env:main:Time of iteration 29: 16
Env:main:Test 30
Env:main:Test 30
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#   A#
# a  #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
# a A#
#  a #
##a ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.159999,<1, 1>=0.019999,<1, 3>=0.639999,<2, 2>=0.159999]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
# aaA#
# a a#
## a##
# a  #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.2,<1, 3>=0.8]
######
#  aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.02,<0, 3>=0.02,<1, 2>=0.24,<1, 3>=0.72]
######
# a a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.076923,<1, 2>=0.923076]
######
# a A#
#  a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.153846,<1, 3>=0.738461,<2, 2>=0.092307]
######
# aaA#
# a a#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.172413,<1, 3>=0.827586]
######
#  aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.017241,<0, 3>=0.017241,<1, 2>=0.220689,<1, 3>=0.744827]
######
# a a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=1.0]
######
#   A#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.8,(<1, 2>-<1, 3>)=0.1]
######
#   a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -17.623324337518003
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.708204449459455
Env:main:Time of iteration 30: 4
Env:main:Test 31
Env:main:Test 31
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
# a  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#  a #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#    #
#b  B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#    #
#    #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#    #
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#    #
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.069767,<3, 1>=0.372093,<4, 1>=0.558139]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#    #
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.015228,<3, 1>=0.010152,<4, 1>=0.974619]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109644,<4, 1>=0.098477,<4, 2>=0.779695]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998050]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099805,<4, 2>=0.099805,<4, 3>=0.798440]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 42.443151150629575
Env:runForbidden:All agents are done, Sum of discounted rewards: 22.918367150629575
Env:main:Time of iteration 31: 24
Env:main:Test 32
Env:main:Test 32
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#aa A#
#aaa #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
# a A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#aaa #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aaaa#
##aa##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a aA#
#   a#
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
######
#aaaa#
#a aa#
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.030303,<4, 0>=0.484848,<4, 2>=0.484848]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: w -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.048484,<3, 2>=0.072727,<4, 0>=0.436363,<4, 1>=0.387878,<4, 2>=0.048484]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.894409,<4, 2>=0.099378]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089440,<4, 0>=0.089440,<4, 1>=0.715527,<4, 3>=0.080124]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109756,<3, 2>=0.012195,<4, 1>=0.878048]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010975,<3, 1>=0.175609,<4, 0>=0.010975,<4, 1>=0.087804,<4, 2>=0.703658]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.013468,<4, 0>=0.015151,<4, 2>=0.971380]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.097138,<3, 3>=0.012121,<4, 1>=0.012121,<4, 2>=0.097138,<4, 3>=0.778451]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -17.487091094142826
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.34112240496485
Env:main:Time of iteration 32: 6
Env:main:Test 33
Env:main:Test 33
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.67985613530799
Env:main:Time of iteration 33: 4
Env:main:Test 34
Env:main:Test 34
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#aa A#
#aaa #
##  ##
#bb  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#aaa #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aaaa#
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.5,<0, 2>=0.470802,<1, 3>=0.029197]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#   a#
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.050000,<0, 1>=0.400000,<0, 2>=0.047080,<0, 3>=0.379562,<1, 0>=0.050000,<1, 2>=0.047080,<1, 3>=0.026277]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
######
#aaaa#
#a aa#
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.063682390415998
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.26784639656146
Env:main:Time of iteration 34: 19
Env:main:Test 35
Env:main:Test 35
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#a   #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66305757395492
Env:main:Time of iteration 35: 22
Env:main:Test 36
Env:main:Test 36
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66305757395492
Env:main:Time of iteration 36: 23
Env:main:Test 37
Env:main:Test 37
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#a   #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aa  #
##  ##
#b   #
#bb B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#a aA#
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaa#
#a a #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.063682390415998
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.764531108691678
Env:main:Time of iteration 37: 14
Env:main:Test 38
Env:main:Test 38
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.75,<3, 1>=0.25]
######
#a  A#
#    #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.025,<3, 0>=0.075000,<3, 1>=0.600000,<3, 2>=0.2,<4, 0>=0.075000,<4, 1>=0.025]
######
#aa A#
#a   #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.017543,<3, 1>=0.982456]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa  #
##b ##
# b  #
#   B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.992405]
GridAgent:decreaseTimer:Agent b timer: 1
######
#   A#
# a  #
##b ##
# b  #
#   B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.996730]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#a a #
##b ##
# b  #
#   B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974619,<1, 0>=0.015228,<1, 1>=0.010152]
######
# a A#
#aa  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098477,<0, 2>=0.779695,<1, 1>=0.109644]
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998050]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099805,<0, 3>=0.798440,<1, 2>=0.099805]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.32541206813946
Env:runForbidden:All agents are done, Sum of discounted rewards: -37.38909445855546
Env:main:Time of iteration 38: 18
Env:main:Test 39
Env:main:Test 39
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.75,<3, 1>=0.25]
######
#aa A#
#aaa #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.025,<3, 0>=0.075000,<3, 1>=0.600000,<3, 2>=0.2,<4, 0>=0.075000,<4, 1>=0.025]
######
# a A#
#aaa #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aaaa#
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aaaa#
##aa##
#bb  #
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
GridAgent:decreaseTimer:Agent b timer: 0
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.65642699821535
Env:main:Time of iteration 39: 16
Env:main:Test 40
Env:main:Test 40
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#aa A#
#aaa #
##  ##
#bb  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.6816
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
######
#aaaA#
#aaaa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.763915110846717
Env:runForbidden:All agents are done, Sum of discounted rewards: -38.44551511084671
Env:main:Time of iteration 40: 11
Env:main:Test 41
Env:main:Test 41
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
#aa  #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#a aA#
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaa#
#a a #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.913045566511837
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.926882501142156
Env:main:Time of iteration 41: 4
Env:main:Test 42
Env:main:Test 42
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.679156,<0, 2>=0.302107,<1, 3>=0.018735]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#a aA#
#   a#
##  ##
#bb  #
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: w -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.611241,<0, 1>=0.241686,<0, 2>=0.030210,<1, 0>=0.067915,<1, 2>=0.045199]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aaaa#
#a aa#
##  ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.681188,<1, 0>=0.191419,<1, 2>=0.127392]
GridAgent:step:Agent b: e -> <2, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a a #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.221254,<0, 1>=0.544950,<0, 2>=0.170033,<1, 0>=0.019141,<1, 1>=0.031881,<1, 3>=0.012739]
GridAgent:step:Agent b: s -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa a#
##bb##
# b b#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.913045566511837
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.024590,<2, 2>=0.057377,<3, 1>=0.918032]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##bb##
# b  #
#   B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.091803,<3, 1>=0.019672,<3, 2>=0.137704,<4, 1>=0.734426]
######
#    #
#    #
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011147,<3, 1>=0.029508,<3, 3>=0.013770,<4, 0>=0.146885,<4, 1>=0.603278,<4, 2>=0.183606]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017594,<3, 1>=0.015524,<3, 2>=0.013454,<4, 1>=0.952193]
######
#    #
#    #
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109332,<3, 2>=0.012506,<3, 3>=0.010763,<4, 1>=0.096771,<4, 2>=0.763100]
######
#    #
# bb #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.013877,<4, 2>=0.983853]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098385,<3, 3>=0.012489,<4, 2>=0.098385,<4, 3>=0.788470]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 42.91227388952482
Env:runForbidden:All agents are done, Sum of discounted rewards: 23.999228323012982
Env:main:Time of iteration 42: 42
Env:main:Test 43
Env:main:Test 43
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#a   #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#aaaA#
#aa  #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.558139,<1, 0>=0.069767,<1, 1>=0.372093]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
# a A#
#aa  #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.093023,<0, 2>=0.446511,<1, 1>=0.111627,<1, 2>=0.297674,<2, 1>=0.037209]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.16985943177059
Env:main:Time of iteration 43: 5
Env:main:Test 44
Env:main:Test 44
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
#aa  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.529411,<1, 1>=0.470588]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
GridAgent:decreaseTimer:Agent b timer: 1
######
#   A#
#aa  #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
GridAgent:decreaseTimer:Agent b timer: 0
######
#   A#
# a  #
##  ##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#  a #
##a ##
#bbb #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.111028,<4, 1>=0.785625,<4, 2>=0.097645]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
# a a#
##aa##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.994379]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#   a#
##  ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.102261,<4, 1>=0.099513,<4, 2>=0.795637]
######
#aaaa#
#a aa#
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998219]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099821,<4, 2>=0.099821,<4, 3>=0.798709]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.47011320014087
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.358100298966807
Env:main:Time of iteration 44: 32
Env:main:Test 45
Env:main:Test 45
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.84
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#    #
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#    #
#    #
##  ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111028,<4, 1>=0.098203,<4, 2>=0.777261]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997138]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099713,<4, 2>=0.099713,<4, 3>=0.797774]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 25.988213499107676
Env:main:Time of iteration 45: 11
Env:main:Test 46
Env:main:Test 46
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aaaa#
##  ##
#bb  #
#bbbB#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
# a A#
#aaa #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.978369,<1, 0>=0.017470]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
# a A#
#aaa #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.980681,<1, 0>=0.017512]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098186,<0, 2>=0.784607,<1, 1>=0.112077]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.83663205047543
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.67656011812943
Env:main:Time of iteration 46: 42
Env:main:Test 47
Env:main:Test 47
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#a   #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#aaaA#
#aa  #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#a aA#
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.26784639656146
Env:main:Time of iteration 47: 5
Env:main:Test 48
Env:main:Test 48
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#a  A#
#    #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aa A#
#a   #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.085714,<3, 1>=0.228571,<4, 1>=0.685714]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.022857,<3, 1>=0.137142,<3, 2>=0.182857,<4, 1>=0.091428,<4, 2>=0.548571]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.65642699821535
Env:main:Time of iteration 48: 9
Env:main:Test 49
Env:main:Test 49
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#a  A#
#    #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.072727,<3, 0>=0.027272,<3, 1>=0.218181,<3, 2>=0.581818,<4, 0>=0.027272,<4, 1>=0.072727]
######
#aa A#
#a   #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.013582,<3, 0>=0.035653,<3, 1>=0.095076,<3, 2>=0.760611,<4, 1>=0.095076]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa  #
##b ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.038545,<3, 1>=0.034262,<3, 2>=0.822305,<4, 1>=0.102788]
GridAgent:decreaseTimer:Agent b timer: 1
######
#   A#
# a  #
##b ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.039519,<3, 1>=0.011709,<3, 2>=0.843079,<4, 1>=0.105384]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#a a #
##b ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.088505,<3, 3>=0.084307,<4, 0>=0.042153,<4, 1>=0.093675,<4, 2>=0.685001]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa a#
##bb##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974619,<1, 0>=0.015228,<1, 1>=0.010152]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.103896,<4, 0>=0.051948,<4, 2>=0.844155]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#aa  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.109644,<0, 1>=0.787817,<0, 2>=0.097461]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.084415,<3, 3>=0.093506,<4, 1>=0.041558,<4, 2>=0.084415,<4, 3>=0.685714]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aaa #
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.994871]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.329931364116604
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099551,<0, 2>=0.796025,<1, 1>=0.102051]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998311]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099831,<0, 3>=0.798778,<1, 2>=0.099831]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 43.38613524194427
Env:runForbidden:All agents are done, Sum of discounted rewards: 88.71606660606088
Env:main:Time of iteration 49: 35
Env:main:Sum of discounted rewards: [-38.289, 26.807, 28.94, 91.656, 18.103, 91.661, 90.665, 23.705, 86.945, 26.807, 93.68, 93.171, 25.773, 24.495, -37.246, 92.17, 89.693, 24.587, 27.776, 91.188, 92.16, -19.788, 26.303, 25.435, 20.386, 92.663, -34.868, 26.303, 27.776, 26.147, 28.708, 22.918, 28.341, 93.68, 27.268, 92.663, 92.663, 26.765, -37.389, 91.656, -38.446, 27.927, 23.999, 92.17, 27.358, 25.988, 91.677, 27.268, 91.656, 88.716]
Env:main:ADR: 43.60784844521008
Env:main:std: 5.951190500735709
Env:main:38% Solved
Env:main:0% of the tests timed out
Env:main:32% of the tests resulted in one or more agents to give up
Env:main:Time elapsed (s): 964
Env:main:Average runtime (s): 19.28
Env:main:parameters:
Env:main:	initialTimer: 3
Env:main:	distanceThreshold: 1
