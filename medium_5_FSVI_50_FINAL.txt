Env:main:Test 0
Env:main:Test 0
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.970326,<1, 0>=0.017804,<1, 1>=0.010089]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#aaa #
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098041,<0, 2>=0.776439,<1, 1>=0.111275]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aaaa#
##aa##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.2158407984
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.069767,<3, 1>=0.372093,<4, 1>=0.558139]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.092783,<3, 1>=0.164948,<4, 1>=0.742268]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.016494,<3, 1>=0.148453,<3, 2>=0.131958,<4, 1>=0.090721,<4, 2>=0.593814]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.032693,<3, 1>=0.174364,<3, 2>=0.464971,<4, 1>=0.319667]
######
#    #
#    #
##b ##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.017436,<2, 2>=0.053139,<3, 1>=0.058951,<3, 2>=0.139491,<3, 3>=0.371977,<4, 1>=0.049403,<4, 2>=0.302231]
######
#    #
# b  #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.549061,<4, 2>=0.446112]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.411796,<3, 3>=0.494155,<4, 1>=0.045093,<4, 3>=0.044611]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.893750,<4, 1>=0.097870]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.089375,<3, 1>=0.016490,<3, 3>=0.715000,<4, 2>=0.167671]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.809272,<4, 2>=0.189778]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.232750,<3, 3>=0.728345,<4, 1>=0.019072,<4, 3>=0.018977]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.999869]
######
#    #
#    #
##  ##
#   b#
#b  B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.099986,<4, 3>=0.799895]
######
#    #
#    #
##  ##
#  bb#
#bb b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 41.06374311830472
Env:runForbidden:All agents are done, Sum of discounted rewards: 21.847902319904723
Env:main:Time of iteration 0: 6
Env:main:Test 1
Env:main:Test 1
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
#aa  #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#a aA#
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaa#
#a a #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.17145685463146
Env:main:Time of iteration 1: 4
Env:main:Test 2
Env:main:Test 2
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
# a  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.017,<4, 0>=0.290000,<4, 1>=0.545,<4, 2>=0.129]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#  a #
##a ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017804,<3, 1>=0.010089,<4, 1>=0.970326]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
# a a#
##aa##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.111275,<4, 1>=0.784332,<4, 2>=0.098456]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.994357]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.063682390415998
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.102264,<4, 1>=0.796147,<4, 2>=0.100458]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.999147]
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.100352,<4, 1>=0.099934,<4, 2>=0.799328]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.999827]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099982,<4, 2>=0.099982,<4, 3>=0.799872]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 44.34826572997068
Env:runForbidden:All agents are done, Sum of discounted rewards: 25.28458333955468
Env:main:Time of iteration 2: 9
Env:main:Test 3
Env:main:Test 3
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.84
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#    #
#    #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.072727,<3, 0>=0.027272,<3, 1>=0.218181,<3, 2>=0.581818,<4, 0>=0.027272,<4, 1>=0.072727]
######
#    #
#    #
##b ##
#bbb #
#bb B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.021818,<2, 2>=0.116363,<3, 1>=0.036363,<3, 2>=0.174545,<3, 3>=0.465454,<4, 1>=0.050909,<4, 2>=0.116363]
######
#    #
# b  #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.792569,<4, 2>=0.198142]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.237770,<3, 3>=0.713312,<4, 1>=0.020743,<4, 3>=0.019814]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.027939,<3, 2>=0.894062,<4, 1>=0.077997]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.089406,<3, 1>=0.030151,<3, 3>=0.715250,<4, 2>=0.151804]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.822269,<4, 2>=0.174518]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.221841,<3, 3>=0.740042,<4, 1>=0.017773,<4, 3>=0.017451]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010610,<3, 2>=0.916003,<4, 1>=0.073386]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.091600,<3, 1>=0.015826,<3, 3>=0.732802,<4, 2>=0.150309]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8288,<4, 2>=0.169999]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.21888,<3, 3>=0.74592,<4, 1>=0.017119,<4, 3>=0.016999]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.923700,<4, 1>=0.072248]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.092370,<3, 1>=0.010465,<3, 3>=0.738960,<4, 2>=0.150168]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.830727,<4, 2>=0.168817]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.218126,<3, 3>=0.747654,<4, 1>=0.016927,<4, 3>=0.016881]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.999939]
######
#    #
#    #
##  ##
#   b#
#b  B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.099993,<4, 3>=0.799951]
######
#    #
#    #
##  ##
#  bb#
#bb b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 40.16697463025046
Env:runForbidden:All agents are done, Sum of discounted rewards: 20.326974630250458
Env:main:Time of iteration 3: 6
Env:main:Test 4
Env:main:Test 4
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#aa A#
#aaa #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
# a A#
#aaa #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
#aaaa#
##  ##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
######
# a A#
#aaa #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.111028,<0, 1>=0.785625,<0, 2>=0.097645]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: w -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.070437,<4, 0>=0.45,<4, 1>=0.376642,<4, 2>=0.047080]
######
#aaaA#
#aaaa#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.994379]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.100587,<3, 2>=0.141703,<4, 1>=0.757709]
######
# a A#
#aaa #
##  ##
#b b #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099513,<0, 2>=0.795637,<1, 1>=0.102261]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010058,<3, 1>=0.024229,<3, 3>=0.014170,<4, 0>=0.156240,<4, 1>=0.606167,<4, 2>=0.189133]
######
#aaaA#
#aaaa#
##aa##
#bb b#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998219]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.016111,<3, 1>=0.012936,<4, 1>=0.970951]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099821,<0, 3>=0.798709,<1, 2>=0.099821]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.109984,<4, 1>=0.787110,<4, 2>=0.097095]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#bbb #
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.83663205047543
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.994019]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.102336,<4, 1>=0.099469,<4, 2>=0.795379]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997899]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099789,<4, 2>=0.099789,<4, 3>=0.798483]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 42.91227388952482
Env:runForbidden:All agents are done, Sum of discounted rewards: 87.74890594000024
Env:main:Time of iteration 4: 6
Env:main:Test 5
Env:main:Test 5
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#aa A#
#aaa #
##  ##
#bb  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aaaa#
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.970326,<1, 0>=0.017804,<1, 1>=0.010089]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#aaa #
##b ##
#  b #
# b B#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.111275,<0, 1>=0.784332,<0, 2>=0.098456]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aaaa#
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <1, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.994357]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#aaa #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.102264,<0, 1>=0.796147,<0, 2>=0.100458]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aaaa#
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.999147]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.913045566511837
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099934,<0, 2>=0.799328,<1, 1>=0.100352]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.999827]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099982,<0, 3>=0.799872,<1, 2>=0.099982]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.34826572997068
Env:runForbidden:All agents are done, Sum of discounted rewards: 25.43522016345884
Env:main:Time of iteration 5: 8
Env:main:Test 6
Env:main:Test 6
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.26784639656146
Env:main:Time of iteration 6: 4
Env:main:Test 7
Env:main:Test 7
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#   A#
# a  #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
# a A#
#a a #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
#aa a#
##  ##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.484848,<0, 2>=0.484848,<1, 3>=0.030303]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
######
#a aA#
#   a#
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.048484,<0, 1>=0.387878,<0, 2>=0.048484,<0, 3>=0.390909,<1, 0>=0.048484,<1, 2>=0.048484,<1, 3>=0.027272]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111028,<4, 1>=0.098203,<4, 2>=0.777261]
######
#aaaa#
#a aa#
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997138]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099713,<4, 2>=0.099713,<4, 3>=0.797774]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66814156676168
Env:main:Time of iteration 7: 3
Env:main:Test 8
Env:main:Test 8
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
#aa  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.027272,<0, 1>=0.072727,<1, 0>=0.027272,<1, 1>=0.218181,<1, 2>=0.581818,<2, 1>=0.072727]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#aaa #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.095076,<1, 0>=0.035653,<1, 1>=0.095076,<1, 2>=0.760611,<2, 1>=0.013582]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
# a A#
#aaa #
##a ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.038030,<0, 1>=0.152122,<0, 2>=0.617996,<1, 0>=0.013073,<1, 1>=0.090492,<1, 3>=0.076061]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##aa##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.051948,<0, 2>=0.844155,<1, 3>=0.103896]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#a aA#
#   a#
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.041558,<0, 2>=0.084415,<0, 3>=0.685714,<1, 2>=0.084415,<1, 3>=0.093506]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaa#
#a aa#
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.913045566511837
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.416885797604767
Env:main:Time of iteration 8: 4
Env:main:Test 9
Env:main:Test 9
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66305757395492
Env:main:Time of iteration 9: 4
Env:main:Test 10
Env:main:Test 10
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109607,<3, 2>=0.097428,<4, 1>=0.791610]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aa  #
##  ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011096,<3, 1>=0.020703,<4, 0>=0.166847,<4, 1>=0.634370,<4, 2>=0.157104]
######
#a aA#
#    #
##  ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017005,<3, 1>=0.010576,<4, 1>=0.972210]
######
#aaaa#
#a a #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.110825,<4, 1>=0.098278,<4, 2>=0.777789]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997606]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099760,<4, 2>=0.099760,<4, 3>=0.798106]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.16985943177059
Env:main:Time of iteration 10: 6
Env:main:Test 11
Env:main:Test 11
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.791610,<1, 0>=0.109607,<1, 2>=0.097428]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#aaa #
##  ##
#bb  #
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166847,<0, 1>=0.634370,<0, 2>=0.157104,<1, 0>=0.011096,<1, 1>=0.020703]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.085714,<3, 1>=0.228571,<4, 1>=0.685714]
######
#aaaA#
#aaaa#
##  ##
#bb  #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.031428,<3, 2>=0.022857,<4, 0>=0.137142,<4, 1>=0.731428,<4, 2>=0.068571]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
# a  #
##  ##
#bbb #
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.039855,<3, 2>=0.028985,<4, 1>=0.927536]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#a a #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.124637,<4, 1>=0.744927,<4, 2>=0.115942]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aa a#
##  ##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974619,<1, 0>=0.015228,<1, 1>=0.010152]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.011904,<4, 0>=0.511904,<4, 2>=0.476190]
######
# a A#
#aa  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.109644,<0, 1>=0.787817,<0, 2>=0.097461]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: w -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.051190,<3, 2>=0.057142,<4, 0>=0.460714,<4, 1>=0.380952,<4, 2>=0.047619]
######
#aaaA#
#aaa #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.994871]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.010846,<4, 0>=0.494278,<4, 1>=0.356019,<4, 2>=0.122050]
######
# a A#
#aaa #
##  ##
#bbbb#
#bbbb#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.102051,<0, 1>=0.796410,<0, 2>=0.100512]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.794444,<4, 2>=0.196168]
######
#aaaA#
#aaaa#
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.503478,<0, 2>=0.495888]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: w -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.079444,<3, 2>=0.027126,<4, 0>=0.715,<4, 1>=0.156934,<4, 2>=0.019616]
######
#a aA#
#   a#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.050347,<0, 1>=0.402783,<0, 2>=0.049588,<0, 3>=0.396774,<1, 0>=0.050347,<1, 2>=0.049588]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.079519,<3, 1>=0.079323,<3, 3>=0.022567,<4, 0>=0.079519,<4, 1>=0.588245,<4, 2>=0.130344,<4, 3>=0.015802]
######
#aaaa#
#a aa#
## b##
#bbbb#
#bbbb#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.208661,<0, 1>=0.550739,<0, 2>=0.198301,<1, 1>=0.016567]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.114075,<3, 1>=0.037931,<4, 1>=0.843877]
######
#aaaa#
#aaaa#
## b##
#bbb #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 2>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.975273,<1, 0>=0.014780]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -17.760933674260613
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098505,<0, 2>=0.780235,<1, 1>=0.109351]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997938]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099793,<0, 3>=0.798367,<1, 2>=0.099793]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 40.613105687121674
Env:runForbidden:All agents are done, Sum of discounted rewards: 22.85217201286106
Env:main:Time of iteration 11: 7
Env:main:Test 12
Env:main:Test 12
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#aa A#
#aaa #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
# a A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#aaa #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#aaaA#
#aaaa#
##aa##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#a aA#
#   a#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.763915110846717
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.56761367613074
Env:main:Time of iteration 12: 4
Env:main:Test 13
Env:main:Test 13
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
# a  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#  a #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
# a a#
##aa##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#a aA#
#   a#
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaa#
#a aa#
##  ##
#    #
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.17145685463146
Env:main:Time of iteration 13: 4
Env:main:Test 14
Env:main:Test 14
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
# a  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#  a #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
# a a#
##aa##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.085714,<3, 1>=0.228571,<4, 1>=0.685714]
######
#a aA#
#   a#
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.101123,<3, 1>=0.089887,<4, 1>=0.808988]
######
#aaaa#
#a aa#
##  ##
#bb  #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010112,<3, 1>=0.161797,<3, 2>=0.071910,<4, 0>=0.010112,<4, 1>=0.089887,<4, 2>=0.647191]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.16985943177059
Env:main:Time of iteration 14: 3
Env:main:Test 15
Env:main:Test 15
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.970326,<1, 0>=0.017804,<1, 1>=0.010089]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#aaa #
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098041,<0, 2>=0.776439,<1, 1>=0.111275]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aaaa#
##aa##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.995889]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.069767,<3, 1>=0.372093,<4, 1>=0.558139]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099588,<0, 3>=0.796894,<1, 2>=0.099588]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.044186,<3, 2>=0.037209,<4, 0>=0.111627,<4, 1>=0.744186,<4, 2>=0.055813]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#bbb #
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.210232,<4, 1>=0.617674,<4, 2>=0.148837]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#bbbb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.986382]
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.105174,<4, 1>=0.099071,<4, 2>=0.789217]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997840]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099784,<4, 2>=0.099784,<4, 3>=0.798384]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.182157947458066
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.149370839519392
Env:main:Time of iteration 15: 6
Env:main:Test 16
Env:main:Test 16
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
#aa  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.218181,<0, 1>=0.581818,<1, 0>=0.099999,<1, 1>=0.027272,<1, 2>=0.072727]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#aaa #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109607,<3, 2>=0.097428,<4, 1>=0.791610]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a  A#
#    #
##  ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011096,<3, 1>=0.020703,<4, 0>=0.166847,<4, 1>=0.634370,<4, 2>=0.157104]
######
#aa A#
#a   #
##  ##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017005,<3, 1>=0.010576,<4, 1>=0.972210]
######
# a A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.110825,<4, 1>=0.098278,<4, 2>=0.777789]
######
#aaaA#
#aa  #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997606]
######
#a aA#
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099760,<4, 2>=0.099760,<4, 3>=0.798106]
######
#aaaa#
#a a #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.329931364116604
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.329931364116604
Env:runForbidden:All agents are done, Sum of discounted rewards: 90.65986272823321
Env:main:Time of iteration 16: 10
Env:main:Test 17
Env:main:Test 17
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
#aaaa#
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
# a A#
#aaa #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.111028,<0, 1>=0.785625,<0, 2>=0.097645]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaA#
#aaaa#
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.531908,<0, 2>=0.467794]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#a aA#
#   a#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.053190,<0, 1>=0.425526,<0, 2>=0.046779,<0, 3>=0.374265,<1, 0>=0.053190,<1, 2>=0.046779]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: n -> DONE O: DONE_OBS R: -0.04
GridAgent:step:Agent a done! discounted reward: -0.3459310100654364
Env:runForbidden:All agents are done, Sum of discounted rewards: 45.98559777691202
Env:main:Time of iteration 17: 4
Env:main:Test 18
Env:main:Test 18
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
#aa  #
##  ##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.685714,<1, 0>=0.085714,<1, 1>=0.228571]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
######
# a A#
#aa  #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.137142,<0, 1>=0.731428,<0, 2>=0.068571,<1, 0>=0.031428,<1, 2>=0.022857]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111028,<4, 1>=0.098203,<4, 2>=0.777261]
######
#aaaA#
#aaa #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.221714,<0, 1>=0.612571,<0, 2>=0.146285]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997138]
######
#aaaa#
#aaaa#
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.598765,<0, 2>=0.395061]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099713,<4, 2>=0.099713,<4, 3>=0.797774]
######
#a aA#
#   a#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: w -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.538888,<0, 1>=0.316049,<0, 2>=0.039506,<1, 0>=0.059876,<1, 2>=0.044444]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.751835,<1, 0>=0.142437,<1, 2>=0.105726]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.189133,<0, 1>=0.601468,<0, 2>=0.159765,<1, 0>=0.014243,<1, 1>=0.024816,<1, 3>=0.010572]
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.963915,<1, 0>=0.022827,<1, 1>=0.013256]
######
# a A#
#aa  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.097717,<0, 2>=0.771132,<1, 1>=0.114653,<1, 2>=0.010605]
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997048]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099704,<0, 3>=0.797638,<1, 2>=0.099704]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -17.760933674260613
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.067279824847063
Env:main:Time of iteration 18: 4
Env:main:Test 19
Env:main:Test 19
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.67985613530799
Env:main:Time of iteration 19: 3
Env:main:Test 20
Env:main:Test 20
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.558139,<1, 0>=0.069767,<1, 1>=0.372093]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 0
######
# a A#
#aa  #
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.093023,<0, 2>=0.446511,<1, 1>=0.111627,<1, 2>=0.297674,<2, 1>=0.037209]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.211320,<1, 0>=0.015849,<1, 1>=0.084528,<1, 2>=0.676226,<2, 1>=0.012075]
######
# a A#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.029584,<0, 2>=0.236679,<1, 1>=0.035018,<1, 2>=0.067622,<1, 3>=0.540981,<2, 2>=0.077283]
######
#aaaA#
#aaaa#
##aa##
# a  #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.215140,<1, 0>=0.011525,<1, 1>=0.084885,<1, 2>=0.491749,<2, 2>=0.187333]
######
# a A#
#aaa #
##aa##
# a  #
#    #
######

GridAgent:step:Agent a: e -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.030002,<0, 2>=0.221287,<1, 1>=0.031612,<1, 2>=0.086641,<1, 3>=0.393399,<2, 2>=0.206066,<3, 2>=0.019201]
######
#aaaA#
#aaaa#
##aa##
# aa #
# a  #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.149226,<1, 1>=0.052411,<1, 2>=0.430936,<2, 2>=0.341643,<3, 2>=0.013643]
######
# a A#
#aaa #
##aa##
# aa #
# a  #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.207233,<1, 1>=0.024261,<1, 2>=0.598449,<2, 2>=0.158148]
######
# a A#
#aaa #
##aa##
# aa #
# a  #
######

GridAgent:step:Agent a: e -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.023149,<0, 2>=0.225631,<1, 1>=0.027212,<1, 2>=0.035224,<1, 3>=0.478759,<2, 2>=0.187598,<3, 2>=0.015836]
######
#aaaA#
#aaaa#
##aa##
# aaa#
# aa #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=0.120886,<2, 2>=0.833373,<3, 2>=0.030150]
######
#   A#
# a  #
##aa##
# aaa#
# aa #
######

GridAgent:step:Agent a: n -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.096709,<1, 0>=0.012088,<1, 2>=0.678787,<2, 1>=0.083885,<2, 2>=0.107919,<3, 3>=0.011672]
######
# a A#
#aaa #
##aa##
#aaaa#
#aaaa#
######

GridAgent:step:Agent a: e -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010040,<0, 2>=0.145246,<1, 1>=0.027730,<1, 2>=0.013751,<1, 3>=0.543029,<2, 2>=0.221519,<3, 2>=0.013208,<3, 3>=0.012083]
######
#aaaA#
#aaaa#
##aa##
#aaaa#
#aaaa#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.210658,<1, 3>=0.787587]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.021241,<0, 3>=0.021065,<1, 2>=0.247285,<1, 3>=0.708829]
######
#aa a#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=0.999752]
######
#a  A#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.799802,(<1, 2>-<1, 3>)=0.099975]
######
#aa a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 39.72530488394795
Env:runForbidden:All agents are done, Sum of discounted rewards: 86.56523295160194
Env:main:Time of iteration 20: 4
Env:main:Test 21
Env:main:Test 21
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: w -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.099999,<0, 1>=0.08,<1, 0>=0.74,<2, 1>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#aa A#
#a   #
##a ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.69,<0, 1>=0.074,<1, 0>=0.074,<1, 1>=0.138]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aaaA#
#aa  #
##aa##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.374097,<1, 0>=0.374097,<1, 1>=0.232546,<2, 2>=0.013480]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
# a A#
#aa  #
##aa##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent a solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.36953616
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111028,<4, 1>=0.098203,<4, 2>=0.777261]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997138]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099713,<4, 2>=0.099713,<4, 3>=0.797774]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.458677339107677
Env:main:Time of iteration 21: 8
Env:main:Test 22
Env:main:Test 22
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#   A#
#aa  #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: n -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.218181,<0, 1>=0.581818,<1, 0>=0.099999,<1, 1>=0.027272,<1, 2>=0.072727]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#aaa #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.334545,<0, 1>=0.509090,<0, 2>=0.116363,<1, 0>=0.012727,<1, 1>=0.017272]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aaaa#
##bb##
# b b#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.36953616
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
Env:runForbidden:All agents are done, Sum of discounted rewards: -38.433218550416
Env:main:Time of iteration 22: 4
Env:main:Test 23
Env:main:Test 23
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#   A#
# a  #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
# a A#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.079999,<0, 2>=0.649999,<1, 1>=0.159999,<1, 3>=0.079999]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
#aaaA#
#aa a#
## a##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 44.83663205047543
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.16816083745289
Env:main:Time of iteration 23: 4
Env:main:Test 24
Env:main:Test 24
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.67985613530799
Env:main:Time of iteration 24: 3
Env:main:Test 25
Env:main:Test 25
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
# a A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
#aaaa#
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.971499,<1, 0>=0.017348,<1, 1>=0.010532]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
# a A#
#aaa #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098203,<0, 2>=0.777261,<1, 1>=0.111028]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaA#
#aaaa#
##aa##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.997138]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#a aA#
#   a#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099713,<0, 3>=0.797774,<1, 2>=0.099713]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.15974228608513
Env:main:Time of iteration 25: 3
Env:main:Test 26
Env:main:Test 26
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: s -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#   A#
#aa  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.218181,<0, 1>=0.581818,<1, 0>=0.099999,<1, 1>=0.027272,<1, 2>=0.072727]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#aaa #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.031818,<0, 1>=0.235454,<0, 2>=0.472727,<1, 0>=0.031818,<1, 1>=0.138181,<1, 2>=0.021818,<1, 3>=0.058181]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
#aaaa#
##aa##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.056542,<0, 2>=0.840064,<1, 3>=0.103392]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
# b  #
#   B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.045234,<0, 2>=0.084006,<0, 3>=0.682390,<1, 2>=0.084006,<1, 3>=0.093053]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.015228,<3, 1>=0.010152,<4, 1>=0.974619]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109644,<4, 1>=0.098477,<4, 2>=0.779695]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998050]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099805,<4, 2>=0.099805,<4, 3>=0.798440]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.32541206813946
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.514515999514533
Env:main:Time of iteration 26: 6
Env:main:Test 27
Env:main:Test 27
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.272727,<1, 1>=0.727272]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
#aa  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <2, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.027272,<0, 1>=0.072727,<1, 0>=0.027272,<1, 1>=0.218181,<1, 2>=0.581818,<2, 1>=0.072727]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#aaa #
##a ##
#b   #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <2, 1> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#   A#
#    #
##a ##
#b   #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 1> O: 1 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#   A#
#    #
##a ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <2, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<2, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#   A#
#    #
##a ##
#    #
#b bB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=0.8,(<2, 1>-<2, 2>)=0.1]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#   A#
# a  #
##aa##
#b b #
#bbbb#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.639999,(<1, 0>-<1, 1>)=0.079999,<1, 2>=0.159999,(<2, 1>-<2, 2>)=0.019999]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
# a A#
#aaa #
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.698544,<1, 0>=0.087318,<1, 1>=0.029106,<1, 2>=0.174636]
######
# a A#
#aaa #
##aa##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.139708,<0, 1>=0.582120,<0, 2>=0.209563,<1, 0>=0.011642,<1, 1>=0.028690,<1, 3>=0.017463]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.950318,<1, 0>=0.019006,<1, 1>=0.015612,<1, 2>=0.014254]
######
# a A#
#aaa #
##aa##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.096593,<0, 2>=0.761680,<1, 1>=0.110261,<1, 2>=0.012546,<1, 3>=0.011403]
######
#aaaA#
#aaaa#
##aa##
# aa #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.982832,<1, 3>=0.014714]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.098283,<0, 3>=0.787737,<1, 2>=0.098283,<1, 3>=0.013243]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 42.91227388952482
Env:runForbidden:All agents are done, Sum of discounted rewards: 89.24380267650227
Env:main:Time of iteration 27: 6
Env:main:Test 28
Env:main:Test 28
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a aA#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 2>=0.1,<4, 1>=0.8]
######
#aaaa#
#a a #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.913045566511837
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.01,<3, 1>=0.02,<3, 3>=0.01,<4, 0>=0.16,<4, 1>=0.64,<4, 2>=0.16]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.015228,<3, 1>=0.010152,<4, 1>=0.974619]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109644,<4, 1>=0.098477,<4, 2>=0.779695]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998050]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099805,<4, 2>=0.099805,<4, 3>=0.798440]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.182157947458066
Env:runForbidden:All agents are done, Sum of discounted rewards: -37.095203513969906
Env:main:Time of iteration 28: 2
Env:main:Test 29
Env:main:Test 29
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.970326,<1, 0>=0.017804,<1, 1>=0.010089]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#aaa #
##  ##
#bb  #
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098041,<0, 2>=0.776439,<1, 1>=0.111275]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#aaaA#
#aaaa#
##aa##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.995889]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
#a aA#
#   a#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099588,<0, 3>=0.796894,<1, 2>=0.099588]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -19.063682390415998
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 27.26784639656146
Env:main:Time of iteration 29: 5
Env:main:Test 30
Env:main:Test 30
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#a aA#
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#aaaa#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66305757395492
Env:main:Time of iteration 30: 2
Env:main:Test 31
Env:main:Test 31
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.079999,<3, 0>=0.019999,<3, 1>=0.079999,<3, 2>=0.639999,<4, 0>=0.019999,<4, 1>=0.159999]
######
#aa A#
#aaa #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.013318,<3, 0>=0.023307,<3, 1>=0.031076,<3, 2>=0.745837,<4, 1>=0.186459]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aaaa#
##b ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.679156,<0, 2>=0.302107,<1, 3>=0.018735]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.087569,<3, 3>=0.074583,<4, 0>=0.037291,<4, 1>=0.174028,<4, 2>=0.615316]
GridAgent:decreaseTimer:Agent b timer: 1
######
#a aA#
#   a#
##bb##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.611241,<0, 1>=0.241686,<0, 2>=0.030210,<1, 0>=0.067915,<1, 2>=0.045199]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.102564,<4, 0>=0.051282,<4, 2>=0.846153]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaa#
#a aa#
##  ##
#   b#
#b bB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.950127,<0, 2>=0.046960]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.084615,<3, 3>=0.092307,<4, 1>=0.041025,<4, 2>=0.084615,<4, 3>=0.687179]
######
#a aA#
#   a#
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.855114,<0, 1>=0.037568,<1, 0>=0.095012]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.095040,<0, 1>=0.688048,<0, 2>=0.031235,<1, 0>=0.095040,<1, 1>=0.079790]
######
#aaaa#
#aaaa#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.849034,<1, 0>=0.117277,<1, 1>=0.032819]
######
# a A#
#aaa #
## a##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011727,<0, 1>=0.088185,<0, 2>=0.679285,<1, 0>=0.011727,<1, 1>=0.178725,<1, 2>=0.026284]
######
#aaaA#
#aaaa#
##aa##
#  a #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.016960,<0, 2>=0.982368]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.013568,<0, 2>=0.098236,<0, 3>=0.785962,<1, 2>=0.098236]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.182157947458066
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.657770120195927
Env:main:Time of iteration 31: 8
Env:main:Test 32
Env:main:Test 32
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.272727,<3, 1>=0.727272]
######
#a  A#
#    #
##  ##
#bb  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.072727,<3, 0>=0.027272,<3, 1>=0.218181,<3, 2>=0.581818,<4, 0>=0.027272,<4, 1>=0.072727]
######
#aa A#
#a   #
##b ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##  ##
#    #
#b  B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aaaa#
#a a #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#    #
#    #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 43.38613524194427
Env:runForbidden:All agents are done, Sum of discounted rewards: 89.71766402892172
Env:main:Time of iteration 32: 6
Env:main:Test 33
Env:main:Test 33
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
# a A#
#a   #
##  ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
######
#aaaA#
#aa  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: w -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.070437,<4, 0>=0.45,<4, 1>=0.376642,<4, 2>=0.047080]
######
#a aA#
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.100587,<3, 2>=0.141703,<4, 1>=0.757709]
######
#aaaa#
#a a #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.913045566511837
GridAgent:step:Agent b: s -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010058,<3, 1>=0.024229,<3, 3>=0.014170,<4, 0>=0.156240,<4, 1>=0.606167,<4, 2>=0.189133]
######
#    #
#    #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.016111,<3, 1>=0.012936,<4, 1>=0.970951]
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109984,<3, 2>=0.010349,<4, 1>=0.098388,<4, 2>=0.776761]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.994984]
######
#    #
#    #
##b ##
# b  #
#   B#
######

GridAgent:step:Agent b: e -> <2, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.099498,<3, 2>=0.795987,<4, 1>=0.099498]
######
#    #
# b  #
##bb##
# bb #
# b B#
######

GridAgent:step:Agent b: e -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.162407,<3, 1>=0.019899,<3, 3>=0.636789,<4, 1>=0.010000,<4, 2>=0.159197]
######
# b  #
# bb #
##bb##
# bbb#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<1, 1>=0.010773,<2, 2>=0.879277,<3, 1>=0.107737]
######
# b  #
# bb #
##bb##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.096570,<2, 2>=0.089440,<3, 0>=0.010773,<3, 2>=0.714195,<4, 1>=0.086189]
######
#b b #
#bbbb#
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <2, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<1, 1>=0.010518,<2, 2>=0.220335,<3, 1>=0.026894,<3, 3>=0.571356,<4, 2>=0.140371]
######
#bbbb#
#bbbb#
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <2, 2> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<1, 2>=0.015434,<2, 2>=0.865440,<3, 1>=0.105638]
######
#bbb #
#bbbb#
##bb##
# b  #
#   B#
######

GridAgent:step:Agent b: s -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.093162,<2, 2>=0.098899,<3, 0>=0.010563,<3, 2>=0.702916,<4, 1>=0.084510]
######
#bbbb#
#bbbb#
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<1, 1>=0.010391,<1, 2>=0.011180,<2, 2>=0.224098,<3, 1>=0.026218,<3, 3>=0.562332,<4, 2>=0.137900]
######
#bbbb#
#bbbb#
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.801855,<4, 2>=0.196638]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.237496,<3, 3>=0.721669,<4, 1>=0.019814,<4, 3>=0.019663]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.918691,<4, 1>=0.076647]
######
#    #
#    #
##  ##
#b b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.091869,<3, 1>=0.011393,<3, 3>=0.734953,<4, 2>=0.153186]
######
#    #
#    #
## b##
#bb b#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.827085,<4, 2>=0.172389]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.220620,<3, 3>=0.744376,<4, 1>=0.017291,<4, 3>=0.017238]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.999929]
######
#    #
#    #
##  ##
#   b#
#b  B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.099992,<4, 3>=0.799943]
######
#    #
#    #
##  ##
#  bb#
#bb b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 37.16650657474359
Env:runForbidden:All agents are done, Sum of discounted rewards: 18.253461008231756
Env:main:Time of iteration 33: 4
Env:main:Test 34
Env:main:Test 34
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
# a  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#a a #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.079999,<0, 2>=0.649999,<1, 1>=0.159999,<1, 3>=0.079999]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
#aa a#
## a##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.36953616
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.111028,<4, 1>=0.098203,<4, 2>=0.777261]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997138]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099713,<4, 2>=0.099713,<4, 3>=0.797774]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.458677339107677
Env:main:Time of iteration 34: 7
Env:main:Test 35
Env:main:Test 35
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,(<3, 1>-<3, 2>)=0.01,<4, 0>=0.799999,<4, 1>=0.16]
######
#aa A#
#aaa #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.789473,<1, 0>=0.109311,<1, 2>=0.097165]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
# a A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.166396,<0, 1>=0.634817,<0, 2>=0.156680,<1, 0>=0.011336,<1, 1>=0.020647]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.5,<0, 2>=0.470802,<1, 3>=0.029197]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
#a aA#
#   a#
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: w -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.450000,<0, 1>=0.376642,<0, 2>=0.047080,<1, 0>=0.050000,<1, 2>=0.070437]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.030303,<4, 2>=0.969696]
######
#aaaa#
#a aa#
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 2> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.757709,<1, 0>=0.100587,<1, 2>=0.141703]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.096969,<4, 1>=0.024242,<4, 2>=0.096969,<4, 3>=0.775757]
######
# a A#
#a a #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.156240,<0, 1>=0.606167,<0, 2>=0.189133,<1, 0>=0.010058,<1, 1>=0.024229,<1, 3>=0.014170]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.434551,<0, 2>=0.526036,<1, 3>=0.039411]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: w -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.391096,<0, 1>=0.420829,<0, 2>=0.052603,<1, 0>=0.043455,<1, 2>=0.084133]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.767351,<1, 0>=0.079237,<1, 2>=0.153410]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.140125,<0, 1>=0.613881,<0, 2>=0.199463,<1, 1>=0.023264,<1, 3>=0.015341]
######
#aaaA#
#aa a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.975095,<1, 0>=0.012586,<1, 1>=0.012318]
######
# a A#
#aa  #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098741,<0, 2>=0.780076,<1, 1>=0.107578]
######
#aaaA#
#aaa #
##a ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.998389]
######
#a aA#
#    #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099838,<0, 3>=0.798711,<1, 2>=0.099838]
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -17.623324337518003
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.708204449459455
Env:main:Time of iteration 35: 4
Env:main:Test 36
Env:main:Test 36
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.84
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.079999,<3, 0>=0.019999,<3, 1>=0.079999,<3, 2>=0.639999,<4, 0>=0.019999,<4, 1>=0.159999]
######
#    #
#    #
##b ##
#bbb #
#bb B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.128,<3, 1>=0.04,<3, 2>=0.064,<3, 3>=0.512,<4, 1>=0.04,<4, 2>=0.191999]
######
#    #
# b  #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.723163,<4, 2>=0.271186]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.289265,<3, 3>=0.650847,<4, 1>=0.027683,<4, 3>=0.027118]
######
#    #
#    #
##  ##
#b bb#
#bb b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.999132]
######
#    #
#    #
##  ##
#   b#
#b  B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.099913,<4, 3>=0.799306]
######
#    #
#    #
##  ##
#  bb#
#bb b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.491528786977458
Env:main:Time of iteration 36: 4
Env:main:Test 37
Env:main:Test 37
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.524784
GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 26.303429499107676
Env:main:Time of iteration 37: 4
Env:main:Test 38
Env:main:Test 38
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,<3, 1>=0.16,<4, 0>=0.02,<4, 1>=0.16,<4, 2>=0.64]
######
# a A#
#a   #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.085714,<3, 1>=0.228571,<4, 1>=0.685714]
######
#aaaA#
#aa  #
##  ##
#bb  #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.101123,<3, 1>=0.089887,<4, 1>=0.808988]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#    #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.107569,<3, 1>=0.031872,<4, 1>=0.860557]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a a #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109905,<3, 1>=0.010854,<4, 1>=0.879240]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#bb  #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010990,<3, 1>=0.175848,<4, 0>=0.010990,<4, 1>=0.089009,<4, 2>=0.703392]
######
#    #
#    #
##b ##
#bbb #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 44.34826572997068
Env:runForbidden:All agents are done, Sum of discounted rewards: 90.67979451694814
Env:main:Time of iteration 38: 5
Env:main:Test 39
Env:main:Test 39
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
######
#aa A#
#a   #
##  ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
######
#aaaA#
#aa  #
##  ##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.029197,<4, 0>=0.500000,<4, 2>=0.470802]
######
#   A#
# a  #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: n -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: w -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.05,<3, 2>=0.070437,<4, 0>=0.45,<4, 1>=0.376642,<4, 2>=0.047080]
######
# a A#
#a a #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent a: n -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.100587,<3, 2>=0.141703,<4, 1>=0.757709]
######
#aaaA#
#aa a#
##  ##
#b b #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.010058,<3, 1>=0.024229,<3, 3>=0.014170,<4, 0>=0.156240,<4, 1>=0.606167,<4, 2>=0.189133]
######
#   A#
# a  #
##  ##
#bb b#
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.8,<1, 0>=0.1,<1, 2>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.016111,<3, 1>=0.012936,<4, 1>=0.970951]
######
# a A#
#a a #
##  ##
#bb  #
# b B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.16,<0, 1>=0.64,<0, 2>=0.16,<1, 0>=0.01,<1, 1>=0.02,<1, 3>=0.01]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.109984,<3, 2>=0.010349,<4, 1>=0.098388,<4, 2>=0.776761]
######
#aaaA#
#aa a#
##b ##
#bbb #
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974619,<1, 0>=0.015228,<1, 1>=0.010152]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.997930]
######
# a A#
#aa  #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.109644,<0, 1>=0.787817,<0, 2>=0.097461]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099793,<4, 2>=0.099793,<4, 3>=0.798344]
######
#aaaA#
#aaa #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.994871]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.182157947458066
######
# a A#
#aaa #
##  ##
#    #
#    #
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099551,<0, 2>=0.796025,<1, 1>=0.102051]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=0.998476]
######
#   A#
# a  #
##aa##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.099847,<1, 2>=0.798906,<2, 1>=0.099847]
######
# a A#
# aa #
##aa##
# aa #
#    #
######

GridAgent:step:Agent a: e -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.159768,<1, 1>=0.019969,<1, 3>=0.639125,<2, 2>=0.160756]
######
# aaA#
# aaa#
##aa##
# aaa#
# aa #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.199987,<1, 3>=0.800012]
######
#  aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: s -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.019998,<0, 3>=0.019998,<1, 2>=0.239991,<1, 3>=0.720011]
######
# a a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 3>=1.0]
######
#   A#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: n -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 3>=0.8,(<1, 2>-<1, 3>)=0.1]
######
#   a#
#  aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 39.72530488394795
Env:runForbidden:All agents are done, Sum of discounted rewards: 21.543146936489883
Env:main:Time of iteration 39: 5
Env:main:Test 40
Env:main:Test 40
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.799999,<0, 1>=0.16,<1, 0>=0.02,(<1, 1>-<1, 2>)=0.01]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.01,<3, 0>=0.090000,(<3, 1>-<3, 2>)=0.08,<4, 0>=0.090000,<4, 1>=0.65]
######
#aa A#
#aaa #
##b ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.106120,<3, 1>=0.031443,<3, 2>=0.094329,<4, 1>=0.766423]
######
#a  A#
#    #
##b ##
#bbb #
# b B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.013756,<3, 1>=0.021392,<4, 0>=0.161538,<4, 1>=0.638293,<4, 2>=0.152105]
######
#aa A#
#a   #
##bb##
#bbbb#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.020767,<3, 1>=0.010765,<4, 1>=0.963599]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa  #
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.112973,<4, 1>=0.779491,<4, 2>=0.100157]
GridAgent:decreaseTimer:Agent b timer: 1
######
#a aA#
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.993419]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaa#
#a a #
##bb##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.102557,<4, 1>=0.099451,<4, 2>=0.794881]
######
#    #
# bb #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998030]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099803,<4, 2>=0.099803,<4, 3>=0.798570]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 44.83663205047543
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.16816083745289
Env:main:Time of iteration 40: 5
Env:main:Test 41
Env:main:Test 41
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#aaa #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.29,<0, 1>=0.544999,<0, 2>=0.128999,<1, 0>=0.01,<1, 1>=0.016999]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aaaa#
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.679156,<0, 2>=0.302107,<1, 3>=0.018735]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#a aA#
#   a#
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.611241,<0, 1>=0.241686,<0, 2>=0.030210,<1, 0>=0.067915,<1, 2>=0.045199]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaa#
#a aa#
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.629798,<0, 1>=0.257977,<0, 2>=0.084655,<1, 1>=0.011332]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#aaaa#
#aaaa#
##  ##
#    #
#b bB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.875729,<0, 2>=0.117712]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#a aA#
#   a#
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.788156,<0, 1>=0.094169,<0, 2>=0.011771,<1, 0>=0.087572,<1, 2>=0.017017]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.33152878697746
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.984477,<0, 2>=0.014703]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.098447,<0, 1>=0.787582,<0, 3>=0.011844,<1, 0>=0.098447]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.887416,<1, 0>=0.110927]
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011092,<0, 1>=0.088741,<0, 2>=0.710098,<1, 0>=0.011092,<1, 1>=0.177483]
######
#aaaA#
#aa a#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=0.999067]
######
#   A#
# a  #
## a##
#    #
#    #
######

GridAgent:step:Agent a: n -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.799253,<1, 0>=0.099906,<1, 2>=0.100652]
######
# a A#
#a a #
##aa##
#    #
#    #
######

GridAgent:step:Agent a: n -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.159850,<0, 1>=0.639403,<0, 2>=0.160447,<1, 1>=0.020130,<1, 3>=0.010065]
######
#aaaA#
#aaaa#
##aa##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.974421,<1, 0>=0.015225,<1, 1>=0.010226]
######
# a A#
#aaa #
##aa##
#    #
#    #
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098464,<0, 2>=0.779548,<1, 1>=0.109622]
######
#aaaA#
#aaaa#
##aa##
# aa #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=0.995812]
######
#   A#
# a  #
##aa##
# aa #
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.796650,<1, 0>=0.099581,<1, 2>=0.099742]
######
# a A#
#aaa #
##aa##
#aaaa#
#    #
######

GridAgent:step:Agent a: n -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.159330,<0, 1>=0.639868,<0, 2>=0.159459,<1, 0>=0.010276,<1, 1>=0.020267]
######
#aaaA#
#aaaa#
##aa##
#aaaa#
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.973041,<1, 0>=0.015627,<1, 1>=0.010273]
######
# a A#
#aaa #
##aa##
#aaaa#
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.098331,<0, 2>=0.778532,<1, 1>=0.109807]
######
#aaaA#
#aaaa#
##aa##
#aaaa#
#aaaa#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.996977]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 2>=0.099697,<0, 3>=0.797684,<1, 2>=0.099697]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 38.42661960358981
Env:runForbidden:All agents are done, Sum of discounted rewards: 84.75814839056727
Env:main:Time of iteration 41: 4
Env:main:Test 42
Env:main:Test 42
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a  A#
#    #
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: e -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.010344,<2, 2>=0.024137,<3, 1>=0.386206,<4, 1>=0.579310]
######
#aa A#
#a   #
##bb##
# b  #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.2158407984
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.011212,<3, 1>=0.179405,<4, 1>=0.807322]
######
#    #
#    #
##bb##
# b  #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.068646,<4, 1>=0.926725]
######
#    #
#    #
##bb##
# b  #
# b B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.024058,<4, 1>=0.974386]
######
#    #
#    #
##bb##
# b  #
# b B#
######

GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.097443,<3, 2>=0.019397,<4, 1>=0.099844,<4, 2>=0.779509]
######
#    #
# bb #
##bb##
# bb #
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=1.0]
######
#    #
#    #
##  ##
#    #
#  bB#
######

GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.1,<4, 2>=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  b #
#  bb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.32541206813946
Env:runForbidden:All agents are done, Sum of discounted rewards: -37.54125286653946
Env:main:Time of iteration 42: 5
Env:main:Test 43
Env:main:Test 43
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.02,(<3, 1>-<3, 2>)=0.01,<4, 0>=0.799999,<4, 1>=0.16]
######
#a  A#
#    #
##  ##
#bbb #
#bb B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#aa A#
#a   #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aaaA#
#aa  #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#a aA#
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaa#
#a a #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.015384,<4, 2>=0.984615]
######
#    #
#    #
##  ##
#    #
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.098461,<4, 1>=0.012307,<4, 2>=0.098461,<4, 3>=0.787692]
######
#    #
#    #
##  ##
#b b #
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 45.828213499107676
Env:runForbidden:All agents are done, Sum of discounted rewards: 92.66814156676168
Env:main:Time of iteration 43: 4
Env:main:Test 44
Env:main:Test 44
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -19.84
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#    #
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#    #
#    #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#    #
#    #
##  ##
#b   #
# b B#
######

GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#    #
#    #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#    #
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#    #
#    #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 43.864783072670974
Env:runForbidden:All agents are done, Sum of discounted rewards: 24.024783072670974
Env:main:Time of iteration 44: 4
Env:main:Test 45
Env:main:Test 45
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.17,<0, 1>=0.65,<1, 0>=0.090000,<1, 1>=0.01,<1, 2>=0.08]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aa A#
#aaa #
##  ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a  A#
#    #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.9,<0, 1>=0.1]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: s -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aa A#
#    #
##bb##
# b b#
#bbbB#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.024590,<2, 2>=0.057377,<3, 1>=0.918032]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a  A#
#    #
##bb##
# b  #
#   B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <0, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.091803,<3, 1>=0.019672,<3, 2>=0.137704,<4, 1>=0.734426]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aa A#
#a   #
##bb##
#bbb #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011147,<3, 1>=0.029508,<3, 3>=0.013770,<4, 0>=0.146885,<4, 1>=0.603278,<4, 2>=0.183606]
GridAgent:decreaseTimer:Agent b timer: 2
######
# a A#
#a   #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017594,<3, 1>=0.015524,<3, 2>=0.013454,<4, 1>=0.952193]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaA#
#aa  #
##bb##
#bbb #
# b B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017794,<3, 2>=0.013607,<4, 1>=0.963019]
GridAgent:decreaseTimer:Agent b timer: 0
######
#a aA#
#    #
##bb##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <1, 2>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.61627595973825
######
#aaaa#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent a done! discounted reward: -18.47011320014087
Env:runForbidden:All agents are done, Sum of discounted rewards: -37.08638915987912
Env:main:Time of iteration 45: 12
Env:main:Test 46
Env:main:Test 46
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a  A#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aa A#
#a   #
##b ##
#  b #
# b B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.019999,<0, 1>=0.159999,<0, 2>=0.639999,<1, 0>=0.019999,<1, 1>=0.159999]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#aaaA#
#aa  #
##bb##
# b b#
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.030303,<0, 2>=0.969696]
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.108108,<4, 0>=0.013513,<4, 2>=0.878378]
GridAgent:decreaseTimer:Agent b timer: 1
######
#a aA#
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.024242,<0, 2>=0.096969,<0, 3>=0.775757,<1, 2>=0.096969]
GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.087837,<3, 3>=0.097297,<4, 1>=0.010810,<4, 2>=0.087837,<4, 3>=0.713513]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaa#
#a a #
##  ##
#b bb#
#bbbb#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 46.83992806765399
Env:runForbidden:All agents are done, Sum of discounted rewards: 93.67985613530799
Env:main:Time of iteration 46: 4
Env:main:Test 47
Env:main:Test 47
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <1, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 0> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 0>=0.75,<1, 1>=0.25]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#   A#
#aa  #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.600000,<0, 1>=0.2,<1, 0>=0.1,<1, 1>=0.075000,<1, 2>=0.025]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <3, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#aaa #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.64,<0, 1>=0.279999,<0, 2>=0.04,<1, 0>=0.017499,<1, 1>=0.012499]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 0> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
#aaaA#
#aaaa#
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.937728,<0, 2>=0.058608]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#a aA#
#   a#
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: w -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.843956,<0, 1>=0.046886,<1, 0>=0.093772]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#aaaa#
#a aa#
##  ##
# b  #
#   B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.992675]
GridAgent:step:Agent b: e -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##b ##
#  b #
# b B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.099267,<0, 1>=0.794140,<1, 0>=0.099267]
GridAgent:step:Agent b: s -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.159999,<3, 3>=0.079999,<4, 1>=0.079999,<4, 2>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##bb##
# b b#
#bbbB#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent b solves:
GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888203,<1, 0>=0.111025]
GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -18.763915110846717
######
# a A#
#a a #
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011102,<0, 1>=0.088820,<0, 2>=0.710639,<1, 0>=0.011102,<1, 1>=0.177640]
######
#aaaA#
#aa a#
## a##
#    #
#    #
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015369,<0, 2>=0.983776]
######
#a aA#
#   a#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012295,<0, 2>=0.098377,<0, 3>=0.787106,<1, 2>=0.098377]
######
#aaaa#
#a aa#
##  ##
#    #
#    #
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 43.864783072670974
Env:runForbidden:All agents are done, Sum of discounted rewards: 25.100867961824257
Env:main:Time of iteration 47: 6
Env:main:Test 48
Env:main:Test 48
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: n -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.8,(<1, 0>-<1, 1>)=0.1]
GridAgent:step:Agent b: s -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 0>-<3, 1>)=0.1,<4, 0>=0.8]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 0> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=1.0]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 0> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=1.0]
######
#a  A#
#    #
##  ##
#    #
#b  B#
######

GridAgent:step:Agent a: e -> <0, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<0, 1>=0.8,<1, 0>=0.1]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<4, 0>=0.1,<4, 1>=0.8]
######
#aa A#
#a   #
##  ##
#b   #
#bb B#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 1> O: 3 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.888888,<1, 0>=0.111111]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.111111,<4, 1>=0.888888]
######
# a A#
#a   #
##  ##
#b   #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.011111,<0, 1>=0.088888,<0, 2>=0.711111,<1, 0>=0.011111,<1, 1>=0.177777]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011111,<3, 1>=0.177777,<4, 0>=0.011111,<4, 1>=0.088888,<4, 2>=0.711111]
######
#aaaA#
#aa  #
##  ##
#bb  #
#bbbB#
######

GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.015384,<0, 2>=0.984615]
GridAgent:step:Agent b: ping_to_<1,1> -> <3, 1> O: 2 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=1.0]
######
#a aA#
#    #
##  ##
# b  #
#   B#
######

GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.012307,<0, 2>=0.098461,<0, 3>=0.787692,<1, 2>=0.098461]
GridAgent:step:Agent b: e -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 1>=0.1,<3, 2>=0.8,<4, 1>=0.1]
######
#aaaa#
#a a #
##b ##
#  b #
# b B#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.33152878697746
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.159999,<3, 1>=0.019999,<3, 3>=0.639999,<4, 2>=0.159999]
######
#    #
# b  #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.8,<4, 2>=0.2]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.240000,<3, 3>=0.720000,<4, 1>=0.020000,<4, 3>=0.020000]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 2> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.923076,<4, 1>=0.076923]
######
#    #
#    #
##  ##
#  b #
# b B#
######

GridAgent:step:Agent b: e -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<2, 2>=0.092307,<3, 3>=0.738461,<4, 2>=0.153846]
######
#    #
#    #
## b##
# b b#
# bbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=0.827586,<4, 2>=0.172413]
######
#    #
#    #
##  ##
#   b#
#  bB#
######

GridAgent:step:Agent b: n -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.220689,<3, 3>=0.744827,<4, 1>=0.017241,<4, 3>=0.017241]
######
#    #
#    #
##  ##
#  bb#
# b b#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <3, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 3>=1.0]
######
#    #
#    #
##  ##
#   b#
#   B#
######

GridAgent:step:Agent b: s -> <3, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[(<3, 2>-<3, 3>)=0.1,<4, 3>=0.8]
######
#    #
#    #
##  ##
#  bb#
#   b#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: -20.0
GridAgent:step:Agent b done! discounted reward: -17.623324337518003
Env:runForbidden:All agents are done, Sum of discounted rewards: 28.708204449459455
Env:main:Time of iteration 48: 5
Env:main:Test 49
Env:main:Test 49
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:Agent a starts at <1, 0>
Env:runForbidden:Agent b starts at <3, 0>
######
#   A#
#a   #
##  ##
#b   #
#   B#
######

GridAgent:step:Agent a: e -> <1, 1> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.1,<1, 0>=0.1,<1, 1>=0.8]
GridAgent:step:Agent b: e -> <3, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.1,<3, 1>=0.8,<4, 0>=0.1]
######
#a  A#
#aa  #
##  ##
#bb  #
#b  B#
######

Env:mightCollidingAgents:Agents a, b may collide in <1, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <1, 1> O: 2 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<1, 1>=1.0]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.089999,<3, 2>=0.079999,<4, 0>=0.169999,<4, 1>=0.649999]
GridAgent:decreaseTimer:Agent b timer: 2
######
#   A#
# a  #
##  ##
#bbb #
#bb B#
######

Env:mightCollidingAgents:Agents a, b may collide in <3, 1>
GridAgent:solve:Agent a solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: e -> <1, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.1,<1, 2>=0.8,<2, 1>=0.1]
GridAgent:decreaseTimer:Agent a timer: 2
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.109311,<3, 2>=0.097165,<4, 1>=0.789473]
GridAgent:decreaseTimer:Agent b timer: 1
######
# a A#
#  a #
##a ##
#bbb #
# b B#
######

GridAgent:step:Agent a: n -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.01,<0, 1>=0.08,<0, 2>=0.65,<1, 1>=0.16,<1, 3>=0.08,(<2, 1>-<2, 2>)=0.01]
GridAgent:decreaseTimer:Agent a timer: 1
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.011336,<3, 1>=0.020647,<4, 0>=0.166396,<4, 1>=0.634817,<4, 2>=0.156680]
GridAgent:decreaseTimer:Agent b timer: 0
######
#aaaA#
# a a#
##aa##
#bbbb#
#bbbB#
######

GridAgent:solve:Agent b solves:
Env:mightCollidingAgents:Agents a, b may collide in <2, 1>
Env:mightCollidingAgents:Agents a, b may collide in <2, 2>
GridAgent:solve:Agent a solves:
GridAgent:solve:Agent b solves:
Env:runForbidden:finished finding forbidden states
GridAgent:step:Agent a: ping_to_<3,1> -> <0, 2> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 0>=0.013513,<0, 2>=0.878378,<1, 3>=0.108108]
GridAgent:decreaseTimer:Agent a timer: 0
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 0>=0.017348,<3, 1>=0.010532,<4, 1>=0.971499]
GridAgent:decreaseTimer:Agent b timer: 2
######
#a aA#
#   a#
##  ##
#bbb #
# b B#
######

GridAgent:solve:Agent a solves:
GridAgent:step:Agent a: e -> <0, 3> O: 4 R: -0.04
GridAgent:step:Agent a current belief: bs-1[<0, 1>=0.010810,<0, 2>=0.087837,<0, 3>=0.713513,<1, 2>=0.087837,<1, 3>=0.097297]
GridAgent:step:Agent b: s -> <4, 1> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 0>=0.111028,<4, 1>=0.785625,<4, 2>=0.097645]
GridAgent:decreaseTimer:Agent b timer: 1
######
#aaaa#
#a aa#
##  ##
#bbbb#
#bbbB#
######

GridAgent:step:Agent a: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent a done! discounted reward: 46.83992806765399
GridAgent:step:Agent b: ping_to_<1,1> -> <4, 1> O: 3 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 1>=0.994379]
GridAgent:decreaseTimer:Agent b timer: 0
######
#    #
#    #
##  ##
#bbb #
# b B#
######

GridAgent:solve:Agent b solves:
GridAgent:step:Agent b: e -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 1>=0.102261,<4, 1>=0.099513,<4, 2>=0.795637]
######
#    #
#    #
##bb##
#bbbb#
#bbbB#
######

GridAgent:step:Agent b: ping_to_<1,1> -> <4, 2> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<4, 2>=0.998219]
######
#    #
#    #
##  ##
#   b#
#b bB#
######

GridAgent:step:Agent b: e -> <4, 3> O: 4 R: -0.04
GridAgent:step:Agent b current belief: bs-1[<3, 2>=0.099821,<4, 2>=0.099821,<4, 3>=0.798709]
######
#    #
#    #
##  ##
#b bb#
#bbbb#
######

GridAgent:step:Agent b: DONE_ACT -> DONE O: DONE_OBS R: 50.0
GridAgent:step:Agent b done! discounted reward: 44.83663205047543
Env:runForbidden:All agents are done, Sum of discounted rewards: 91.67656011812943
Env:main:Time of iteration 49: 7
Env:main:Sum of discounted rewards: [21.848, 93.171, 25.285, 20.327, 87.749, 25.435, 27.268, 92.668, 26.417, 92.663, 92.17, 22.852, 27.568, 93.171, 92.17, 28.149, 90.66, 45.986, 28.067, 93.68, 86.565, 26.459, -38.433, 91.168, 93.68, 92.16, 28.515, 89.244, -37.095, 27.268, 92.663, 28.658, 89.718, 18.253, 26.459, 28.708, 26.492, 26.303, 90.68, 21.543, 91.168, 84.758, -37.541, 92.668, 24.025, -37.086, 93.68, 25.101, 28.708, 91.677]
Env:main:ADR: 49.86934261235133
Env:main:std: 5.7285972502232925
Env:main:46% Solved
Env:main:0% of the tests timed out
Env:main:24% of the tests resulted in one or more agents to give up
Env:main:Time elapsed (s): 280
Env:main:Average runtime (s): 5.6
Env:main:parameters:
Env:main:	initialTimer: 3
Env:main:	distanceThreshold: 1
